{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"home/","text":"#DevopsTraineeProgram This repository is used to document the journey for the Devops Trainee program to build foundational knowledge of DevOps. The goal is to tackle each topic through sprints to tackle over 13 areas of DevOps to a foundational knowledge for a full-time position in Resultier. This will not cover all things DevOps but it will cover the areas that will benefit your learning and understanding overall to tackle our end projects. #Week 00 [\u2714\ufe0f] Day 00 \u267e\ufe0f 01 > Introduction #Week 01 What is and why do we use DevOps [\u2714\ufe0f] \u267e\ufe0f 01 > Responsibilities of a DevOps Engineer [\u2714\ufe0f] \u267e\ufe0f 02 > DevOps Lifecycle - Application Focused [\u2714\ufe0f] \u267e\ufe0f 03 > DevOps & Agile [\u2714\ufe0f] \u267e\ufe0f 04 > Plan > Code > Build > Testing > Release > Deploy > Operate > Monitor > [\u2714\ufe0f] \u267e\ufe0f 05 > DevOps - The real stories Learning a Programming Language [\u2714\ufe0f] \u2328\ufe0f 01 > The Big Picture: DevOps & Learning a Programming Language [\u2714\ufe0f] \u2328\ufe0f 02 > Setting up your DevOps environment for Go & Hello World [\u2714\ufe0f] \u2328\ufe0f 03 > Let's explain the Hello World code [\u2714\ufe0f] \u2328\ufe0f 04 > The Go Workspace & Compiling & running code [\u2714\ufe0f] \u2328\ufe0f 05 > Variables, Constants & Data Types [\u2714\ufe0f] \u2328\ufe0f 06 > Getting user input with Pointers and a finished program [\u2714\ufe0f] \u2328\ufe0f 07 > Tweet your progress with our new App Knowing Linux Basics [\u2714\ufe0f] \ud83d\udc27 01 > The Big Picture: DevOps and Linux [\u2714\ufe0f] \ud83d\udc27 02 > Linux Commands for DevOps (Actually everyone) [\u2714\ufe0f] \ud83d\udc27 03 > Managing your Linux System, Filesystem & Storage [\u2714\ufe0f] \ud83d\udc27 04 > Text Editors - nano vs vim [\u2714\ufe0f] \ud83d\udc27 05 > SSH & Web Server(LAMP) [\ud83d\udea7] \ud83d\udc27 06 > Automate tasks with bash scripts [\ud83d\udea7] \ud83d\udc27 07 > Dev workstation setup - All the pretty things #Week 02 Understand Networking [\ud83d\udea7] \ud83c\udf10 01 > The Big Picture: DevOps and Networking [\ud83d\udea7] \ud83c\udf10 02 > The OSI Model - The 7 Layers [\ud83d\udea7] \ud83c\udf10 03 > Network Protocols [\ud83d\udea7] \ud83c\udf10 04 > Network Automation [\ud83d\udea7] \ud83c\udf10 05 > Python for Network Automation [\ud83d\udea7] \ud83c\udf10 06 > Building our Lab [\ud83d\udea7] \ud83c\udf10 07 > Getting Hands-On with Python & Network Stick to one Cloud Provider [\ud83d\udea7] \u2601\ufe0f 01 > The Big Picture: DevOps & The Cloud [\ud83d\udea7] \u2601\ufe0f 02 > Cloud Fundamentals [\ud83d\udea7] \u2601\ufe0f 03 > Cloud Security Models [\ud83d\udea7] \u2601\ufe0f 04 > Cloud Compute Models [\ud83d\udea7] \u2601\ufe0f 05 > Cloud Storage & Database Models [\ud83d\udea7] \u2601\ufe0f 06 > Cloud Networking Models + Azure Management [\ud83d\udea7] \u2601\ufe0f 07 > Cloud Hands-On Scenarios Use Git Effectively [\ud83d\udea7] \ud83d\udcda 01 > The Big Picture: Git - Version Control [\ud83d\udea7] \ud83d\udcda 02 > Installing & Configuring Git [\ud83d\udea7] \ud83d\udcda 03 > Gitting to know Git [\ud83d\udea7] \ud83d\udcda 04 > Staging & Changing [\ud83d\udea7] \ud83d\udcda 05 > Viewing, unstaging, discarding & restoring [\ud83d\udea7] \ud83d\udcda 06 > Social Network for code [\ud83d\udea7] \ud83d\udcda 07 > The Open Source Workflow #Week 03 Containers [\ud83d\udea7] \ud83c\udfd7\ufe0f 01 > The Big Picture: Containers [\ud83d\udea7] \ud83c\udfd7\ufe0f 02 > What is Docker & Getting installed [\ud83d\udea7] \ud83c\udfd7\ufe0f 03 > Docker Images & Hands-On with Docker Desktop [\ud83d\udea7] \ud83c\udfd7\ufe0f 04 > The anatomy of a Docker Image [\ud83d\udea7] \ud83c\udfd7\ufe0f 05 > Docker Compose [\ud83d\udea7] \ud83c\udfd7\ufe0f 06 > Docker Networking & Security [\ud83d\udea7] \ud83c\udfd7\ufe0f 07 > Alternatives to Docker #Week 04 Kubernetes [\ud83d\udea7] \u2638 01 > The Big Picture: Kubernetes [\ud83d\udea7] \u2638 02 > Choosing your Kubernetes platform [\ud83d\udea7] \u2638 03 > Deploying your first Kubernetes Cluster [\ud83d\udea7] \u2638 04 > Setting up a multinode Kubernetes Cluster [\ud83d\udea7] \u2638 05 > Helm Overview - Hands On [\ud83d\udea7] \u2638 06 > Kubernetes Application Deployment [\ud83d\udea7] \u2638 07 > State and Ingress in Kubernetes #Week 05 Learn Infrastructure as Code [\ud83d\udea7] \ud83e\udd16 01 > The Big Picture: IaC [\ud83d\udea7] \ud83e\udd16 02 > An intro to Terraform [\ud83d\udea7] \ud83e\udd16 03 > HashiCorp Configuration Language (HCL) [\ud83d\udea7] \ud83e\udd16 04 > Create a VM with Terraform & Variables [\ud83d\udea7] \ud83e\udd16 05 > Docker Containers, Provisioners & Modules [\ud83d\udea7] \ud83e\udd16 06 > Kubernetes & Multiple Environments [\ud83d\udea7] \ud83e\udd16 07 > Testing, Tools & Alternatives Automate Configuration Management [\ud83d\udea7] \ud83d\udcdc 01 > The Big Picture: Configuration Management [\ud83d\udea7] \ud83d\udcdc 02 > Ansible: Getting Started [\ud83d\udea7] \ud83d\udcdc 03 > Ansible Playbooks [\ud83d\udea7] \ud83d\udcdc 04 > Ansible Playbooks Continued... [\ud83d\udea7] \ud83d\udcdc 05 > Using Roles & Deploying a Loadbalancer [\ud83d\udea7] \ud83d\udcdc 06 > Tags, Variables, Inventory & Database Server config [\ud83d\udea7] \ud83d\udcdc 07 > All other things Ansible - Automation Controller, AWX, Vault #Week 06 Create CI/CD Pipelines [\ud83d\udea7] \ud83d\udd04 01 > The Big Picture: CI/CD Pipelines [\ud83d\udea7] \ud83d\udd04 02 > What is Jenkins? [\ud83d\udea7] \ud83d\udd04 03 > Getting hands on with Jenkins [\ud83d\udea7] \ud83d\udd04 04 > Building a Jenkins pipeline [\ud83d\udea7] \ud83d\udd04 05 > Hello World - Jenkinsfile App Pipeline [\ud83d\udea7] \ud83d\udd04 06 > GitHub Actions Overview [\ud83d\udea7] \ud83d\udd04 07 > Overview #Week 07 Monitoring, Log Management, and Data Visualisation [\ud83d\udea7] \ud83d\udcc8 01 > The Big Picture: Monitoring [\ud83d\udea7] \ud83d\udcc8 02 > Hands-On Monitoring Tools [\ud83d\udea7] \ud83d\udcc8 03 > The Big Picture: Log Management [\ud83d\udea7] \ud83d\udcc8 04 > ELK Stack [\ud83d\udea7] \ud83d\udcc8 05 > Fluentd & FluentBit [\ud83d\udea7] \ud83d\udcc8 06 > EFK Stack [\ud83d\udea7] \ud83d\udcc8 07 > Data Visualisation - Grafana #Week 08 Store & Protect Your Data [\ud83d\udea7] \ud83d\uddc3\ufe0f 01 > The Big Picture: Data Management [\ud83d\udea7] \ud83d\uddc3\ufe0f 02 > Data Services [\ud83d\udea7] \ud83d\uddc3\ufe0f 03 > Backup all the platforms [\ud83d\udea7] \ud83d\uddc3\ufe0f 04 > Hands-On Backup & Recovery [\ud83d\udea7] \ud83d\uddc3\ufe0f 05 > Application Focused Backups [\ud83d\udea7] \ud83d\uddc3\ufe0f 06 > Disaster Recovery [\ud83d\udea7] \ud83d\uddc3\ufe0f 07 > Data & Application Mobility","title":"#DevopsTraineeProgram"},{"location":"home/#devopstraineeprogram","text":"This repository is used to document the journey for the Devops Trainee program to build foundational knowledge of DevOps. The goal is to tackle each topic through sprints to tackle over 13 areas of DevOps to a foundational knowledge for a full-time position in Resultier. This will not cover all things DevOps but it will cover the areas that will benefit your learning and understanding overall to tackle our end projects.","title":"#DevopsTraineeProgram"},{"location":"home/#week-00","text":"[\u2714\ufe0f] Day 00 \u267e\ufe0f 01 > Introduction","title":"#Week 00"},{"location":"home/#week-01","text":"","title":"#Week 01"},{"location":"home/#what-is-and-why-do-we-use-devops","text":"[\u2714\ufe0f] \u267e\ufe0f 01 > Responsibilities of a DevOps Engineer [\u2714\ufe0f] \u267e\ufe0f 02 > DevOps Lifecycle - Application Focused [\u2714\ufe0f] \u267e\ufe0f 03 > DevOps & Agile [\u2714\ufe0f] \u267e\ufe0f 04 > Plan > Code > Build > Testing > Release > Deploy > Operate > Monitor > [\u2714\ufe0f] \u267e\ufe0f 05 > DevOps - The real stories","title":"What is and why do we use DevOps"},{"location":"home/#learning-a-programming-language","text":"[\u2714\ufe0f] \u2328\ufe0f 01 > The Big Picture: DevOps & Learning a Programming Language [\u2714\ufe0f] \u2328\ufe0f 02 > Setting up your DevOps environment for Go & Hello World [\u2714\ufe0f] \u2328\ufe0f 03 > Let's explain the Hello World code [\u2714\ufe0f] \u2328\ufe0f 04 > The Go Workspace & Compiling & running code [\u2714\ufe0f] \u2328\ufe0f 05 > Variables, Constants & Data Types [\u2714\ufe0f] \u2328\ufe0f 06 > Getting user input with Pointers and a finished program [\u2714\ufe0f] \u2328\ufe0f 07 > Tweet your progress with our new App","title":"Learning a Programming Language"},{"location":"home/#knowing-linux-basics","text":"[\u2714\ufe0f] \ud83d\udc27 01 > The Big Picture: DevOps and Linux [\u2714\ufe0f] \ud83d\udc27 02 > Linux Commands for DevOps (Actually everyone) [\u2714\ufe0f] \ud83d\udc27 03 > Managing your Linux System, Filesystem & Storage [\u2714\ufe0f] \ud83d\udc27 04 > Text Editors - nano vs vim [\u2714\ufe0f] \ud83d\udc27 05 > SSH & Web Server(LAMP) [\ud83d\udea7] \ud83d\udc27 06 > Automate tasks with bash scripts [\ud83d\udea7] \ud83d\udc27 07 > Dev workstation setup - All the pretty things","title":"Knowing Linux Basics"},{"location":"home/#week-02","text":"","title":"#Week 02"},{"location":"home/#understand-networking","text":"[\ud83d\udea7] \ud83c\udf10 01 > The Big Picture: DevOps and Networking [\ud83d\udea7] \ud83c\udf10 02 > The OSI Model - The 7 Layers [\ud83d\udea7] \ud83c\udf10 03 > Network Protocols [\ud83d\udea7] \ud83c\udf10 04 > Network Automation [\ud83d\udea7] \ud83c\udf10 05 > Python for Network Automation [\ud83d\udea7] \ud83c\udf10 06 > Building our Lab [\ud83d\udea7] \ud83c\udf10 07 > Getting Hands-On with Python & Network","title":"Understand Networking"},{"location":"home/#stick-to-one-cloud-provider","text":"[\ud83d\udea7] \u2601\ufe0f 01 > The Big Picture: DevOps & The Cloud [\ud83d\udea7] \u2601\ufe0f 02 > Cloud Fundamentals [\ud83d\udea7] \u2601\ufe0f 03 > Cloud Security Models [\ud83d\udea7] \u2601\ufe0f 04 > Cloud Compute Models [\ud83d\udea7] \u2601\ufe0f 05 > Cloud Storage & Database Models [\ud83d\udea7] \u2601\ufe0f 06 > Cloud Networking Models + Azure Management [\ud83d\udea7] \u2601\ufe0f 07 > Cloud Hands-On Scenarios","title":"Stick to one Cloud Provider"},{"location":"home/#use-git-effectively","text":"[\ud83d\udea7] \ud83d\udcda 01 > The Big Picture: Git - Version Control [\ud83d\udea7] \ud83d\udcda 02 > Installing & Configuring Git [\ud83d\udea7] \ud83d\udcda 03 > Gitting to know Git [\ud83d\udea7] \ud83d\udcda 04 > Staging & Changing [\ud83d\udea7] \ud83d\udcda 05 > Viewing, unstaging, discarding & restoring [\ud83d\udea7] \ud83d\udcda 06 > Social Network for code [\ud83d\udea7] \ud83d\udcda 07 > The Open Source Workflow","title":"Use Git Effectively"},{"location":"home/#week-03","text":"","title":"#Week 03"},{"location":"home/#containers","text":"[\ud83d\udea7] \ud83c\udfd7\ufe0f 01 > The Big Picture: Containers [\ud83d\udea7] \ud83c\udfd7\ufe0f 02 > What is Docker & Getting installed [\ud83d\udea7] \ud83c\udfd7\ufe0f 03 > Docker Images & Hands-On with Docker Desktop [\ud83d\udea7] \ud83c\udfd7\ufe0f 04 > The anatomy of a Docker Image [\ud83d\udea7] \ud83c\udfd7\ufe0f 05 > Docker Compose [\ud83d\udea7] \ud83c\udfd7\ufe0f 06 > Docker Networking & Security [\ud83d\udea7] \ud83c\udfd7\ufe0f 07 > Alternatives to Docker","title":"Containers"},{"location":"home/#week-04","text":"","title":"#Week 04"},{"location":"home/#kubernetes","text":"[\ud83d\udea7] \u2638 01 > The Big Picture: Kubernetes [\ud83d\udea7] \u2638 02 > Choosing your Kubernetes platform [\ud83d\udea7] \u2638 03 > Deploying your first Kubernetes Cluster [\ud83d\udea7] \u2638 04 > Setting up a multinode Kubernetes Cluster [\ud83d\udea7] \u2638 05 > Helm Overview - Hands On [\ud83d\udea7] \u2638 06 > Kubernetes Application Deployment [\ud83d\udea7] \u2638 07 > State and Ingress in Kubernetes","title":"Kubernetes"},{"location":"home/#week-05","text":"","title":"#Week 05"},{"location":"home/#learn-infrastructure-as-code","text":"[\ud83d\udea7] \ud83e\udd16 01 > The Big Picture: IaC [\ud83d\udea7] \ud83e\udd16 02 > An intro to Terraform [\ud83d\udea7] \ud83e\udd16 03 > HashiCorp Configuration Language (HCL) [\ud83d\udea7] \ud83e\udd16 04 > Create a VM with Terraform & Variables [\ud83d\udea7] \ud83e\udd16 05 > Docker Containers, Provisioners & Modules [\ud83d\udea7] \ud83e\udd16 06 > Kubernetes & Multiple Environments [\ud83d\udea7] \ud83e\udd16 07 > Testing, Tools & Alternatives","title":"Learn Infrastructure as Code"},{"location":"home/#automate-configuration-management","text":"[\ud83d\udea7] \ud83d\udcdc 01 > The Big Picture: Configuration Management [\ud83d\udea7] \ud83d\udcdc 02 > Ansible: Getting Started [\ud83d\udea7] \ud83d\udcdc 03 > Ansible Playbooks [\ud83d\udea7] \ud83d\udcdc 04 > Ansible Playbooks Continued... [\ud83d\udea7] \ud83d\udcdc 05 > Using Roles & Deploying a Loadbalancer [\ud83d\udea7] \ud83d\udcdc 06 > Tags, Variables, Inventory & Database Server config [\ud83d\udea7] \ud83d\udcdc 07 > All other things Ansible - Automation Controller, AWX, Vault","title":"Automate Configuration Management"},{"location":"home/#week-06","text":"","title":"#Week 06"},{"location":"home/#create-cicd-pipelines","text":"[\ud83d\udea7] \ud83d\udd04 01 > The Big Picture: CI/CD Pipelines [\ud83d\udea7] \ud83d\udd04 02 > What is Jenkins? [\ud83d\udea7] \ud83d\udd04 03 > Getting hands on with Jenkins [\ud83d\udea7] \ud83d\udd04 04 > Building a Jenkins pipeline [\ud83d\udea7] \ud83d\udd04 05 > Hello World - Jenkinsfile App Pipeline [\ud83d\udea7] \ud83d\udd04 06 > GitHub Actions Overview [\ud83d\udea7] \ud83d\udd04 07 > Overview","title":"Create CI/CD Pipelines"},{"location":"home/#week-07","text":"","title":"#Week 07"},{"location":"home/#monitoring-log-management-and-data-visualisation","text":"[\ud83d\udea7] \ud83d\udcc8 01 > The Big Picture: Monitoring [\ud83d\udea7] \ud83d\udcc8 02 > Hands-On Monitoring Tools [\ud83d\udea7] \ud83d\udcc8 03 > The Big Picture: Log Management [\ud83d\udea7] \ud83d\udcc8 04 > ELK Stack [\ud83d\udea7] \ud83d\udcc8 05 > Fluentd & FluentBit [\ud83d\udea7] \ud83d\udcc8 06 > EFK Stack [\ud83d\udea7] \ud83d\udcc8 07 > Data Visualisation - Grafana","title":"Monitoring, Log Management, and Data Visualisation"},{"location":"home/#week-08","text":"","title":"#Week 08"},{"location":"home/#store-protect-your-data","text":"[\ud83d\udea7] \ud83d\uddc3\ufe0f 01 > The Big Picture: Data Management [\ud83d\udea7] \ud83d\uddc3\ufe0f 02 > Data Services [\ud83d\udea7] \ud83d\uddc3\ufe0f 03 > Backup all the platforms [\ud83d\udea7] \ud83d\uddc3\ufe0f 04 > Hands-On Backup & Recovery [\ud83d\udea7] \ud83d\uddc3\ufe0f 05 > Application Focused Backups [\ud83d\udea7] \ud83d\uddc3\ufe0f 06 > Disaster Recovery [\ud83d\udea7] \ud83d\uddc3\ufe0f 07 > Data & Application Mobility","title":"Store &amp; Protect Your Data"},{"location":"Week/00/day01/","text":"Introduction - Week 00 So you want to learn DevOps? Let the journey begin I will share at this point that everyone should have a good look at and maybe create your own mind map for yourself and your interest and position is the following: DevOps Roadmap First Steps - What is DevOps? There are so many blog articles and YouTube videos to list here, but as we start this journey we will focus on spending each topic a day learning something new or about DevOps. We will start with some of the high level of \"what DevOps is\" down to start off this week. Firstly, DevOps is not a tool. You cannot buy it, it is not a software sku or an open source GitHub repository you can download. It is also not a programming language, it is also not some dark art magic either. DevOps is a way to do smarter things in Software Development. DevOps brings together a combination of software development and operations. There are people with all different backgrounds where DevOps is 100% going to benefit the individual, Developers, Operations and QA Engineers all can equally learn these best practices by having a better understanding of DevOps. DevOps is a set of practices that help to reach the goal of this movement: reducing the time between the ideation phase of a product and its release in production to the end-user or whomever it could be an internal team or customer. Another area we will dive into in this first week is around The Agile Methodology DevOps and Agile are widely adopted together to achieve continuous delivery of your Application The high level take away is with a DevOps mindset or culture its about taking a way the long drawn out software release process from potentially years to being able to drop smaller releases more frequently. The other key fundamental to take away here is it's about breaking down silos between the teams I previously mentioned, Developers, Operations and QA. From a DevOps perspective, Development, Testing and Deployment all land with the DevOps team. The final point I will make is to make this as effective and efficient as possible we must leverage Automation Resources My advice is to watch all of the below and hopefully you also picked something up from the text and explanations above. DevOps in 5 Minutes What is DevOps? Easy Way DevOps roadmap 2022 | Success Roadmap 2022 Start your Journey Here Create an account on KodeKloud with your Resultier email. Enroll to DevOps Prerequisites Course Share a screenshot of your progress at the end of the day! See you on the Next Section next week!","title":"1. Introduction"},{"location":"Week/00/day01/#introduction-week-00","text":"So you want to learn DevOps?","title":"Introduction - Week 00"},{"location":"Week/00/day01/#let-the-journey-begin","text":"I will share at this point that everyone should have a good look at and maybe create your own mind map for yourself and your interest and position is the following: DevOps Roadmap","title":"Let the journey begin"},{"location":"Week/00/day01/#first-steps-what-is-devops","text":"There are so many blog articles and YouTube videos to list here, but as we start this journey we will focus on spending each topic a day learning something new or about DevOps. We will start with some of the high level of \"what DevOps is\" down to start off this week. Firstly, DevOps is not a tool. You cannot buy it, it is not a software sku or an open source GitHub repository you can download. It is also not a programming language, it is also not some dark art magic either. DevOps is a way to do smarter things in Software Development. DevOps brings together a combination of software development and operations. There are people with all different backgrounds where DevOps is 100% going to benefit the individual, Developers, Operations and QA Engineers all can equally learn these best practices by having a better understanding of DevOps. DevOps is a set of practices that help to reach the goal of this movement: reducing the time between the ideation phase of a product and its release in production to the end-user or whomever it could be an internal team or customer. Another area we will dive into in this first week is around The Agile Methodology DevOps and Agile are widely adopted together to achieve continuous delivery of your Application The high level take away is with a DevOps mindset or culture its about taking a way the long drawn out software release process from potentially years to being able to drop smaller releases more frequently. The other key fundamental to take away here is it's about breaking down silos between the teams I previously mentioned, Developers, Operations and QA. From a DevOps perspective, Development, Testing and Deployment all land with the DevOps team. The final point I will make is to make this as effective and efficient as possible we must leverage Automation","title":"First Steps - What is DevOps?"},{"location":"Week/00/day01/#resources","text":"My advice is to watch all of the below and hopefully you also picked something up from the text and explanations above. DevOps in 5 Minutes What is DevOps? Easy Way DevOps roadmap 2022 | Success Roadmap 2022","title":"Resources"},{"location":"Week/00/day01/#start-your-journey-here","text":"Create an account on KodeKloud with your Resultier email. Enroll to DevOps Prerequisites Course Share a screenshot of your progress at the end of the day! See you on the Next Section next week!","title":"Start your Journey Here"},{"location":"Week/01/day01-01/","text":"Responsibilities of a DevOps Engineer It was briefly touched on in the first post but now we must get deeper into this concept and understand that there are two main parts when creating an application. We have the Development part where software developers program the application and test it. Then we have the Operations part where the application is deployed and maintained on a server. DevOps is the link between the two To get to grips with DevOps or the tasks in which a DevOps engineer would be carrying out we need to understand the tools or the process and overview of those and how they come together. Everything starts with the application! You will see so much throughout that it is all about the application when it comes to DevOps. Developers will create an application, this can be done with many different technology stacks and lets leave that to the imagination for now as we get into this later. This can also involve many different programming languages, build tools, code repository etc. As a DevOps engineer you won't be programming the application but having a good understanding of the concepts of how a developer works and the systems, tools and processes they are using is key to success. At a very high level you are going to need to know how the application is configured to talk to all of its required services or data services and then also sprinkle a requirement of how this can or should be tested. The application will need to be deployed somewhere, lets keep it generally simple here and make this a server, doesn't matter where but a server. This is then expected to be accessed by the customer or end user depending on the application that has been created. This server needs to run somewhere, on-premises, in a public cloud, serverless. Someone needs to create and configure these servers and get them ready for the application to run. Now this element might land to you as a DevOps engineer to deploy and configure these servers. These servers will have to run an Operating System and generally speaking this is going to be Linux but we have a whole section or week where we cover some of the foundational knowledge you should gain here. It is also likely that we need to communicate with other services in our network or environment, so we also need to have that level of knowledge around networking and configuring that, this might to some degree also land at the feet of the DevOps engineer. Again we will cover this in more detail in a dedicated section talking all things DNS, DHCP, Load Balancing etc. Jack of all trades, Master of none I will say at this point though, you don't need to be a Network or Infrastructure specialist you need a foundational knowledge of how to get things up and running and talking to each other, much the same as maybe having a foundational knowledge of a programming language but you don't need to be a developer. However you might be coming into this as a specialist in an area and that is a great footing to adapt to other areas. You will also most likely not take over the management of these servers or the application on a daily basis. We have been talking about servers but the likelihood is that your application will be developed to run as containers, Which still runs on a server for the most part but you will also need an understanding of not only virtualisation, Cloud Infrastructure as a Service (IaaS) but also containerization as well, this program will be focused and be catered towards containers. High Level Overview On one side we have our developers creating new features and functionality (as well as bug fixes) for the application. On the other side we have some sort of environment, infrastructure or servers which are configured and managed to run this application and communicate with all its required services. The big question is how do we get those features and bug fixes into our production and make it available to those end users? How do we release the new application version? This is one of the main tasks for a DevOps engineer, and the important thing here is not to just figure out how to do this once but we need to do this continuously and in an automated, efficient way which also needs to include testing! This is where we are going to end this day of learning, hopefully this was useful. Over the next few days we are going to dive a little deeper into some more areas of DevOps and then we will get into the sections that dive deeper into the tooling and processes and the benefits of these. Resources My advice is to watch all of the videos below and take notes on your own textbook or agenda. Going forward, try to keep pen and paper on your side, it will help you whenever you want to go back to your notes in the near future! What is DevOps? - TechWorld with Nana What is DevOps? - GitHub YouTube What is DevOps? - IBM YouTube What is DevOps? - AWS What is DevOps? - Microsoft See you in the Next Section .","title":"1. Responsibilities of a DevOps Engineer"},{"location":"Week/01/day01-01/#responsibilities-of-a-devops-engineer","text":"It was briefly touched on in the first post but now we must get deeper into this concept and understand that there are two main parts when creating an application. We have the Development part where software developers program the application and test it. Then we have the Operations part where the application is deployed and maintained on a server.","title":"Responsibilities of a DevOps Engineer"},{"location":"Week/01/day01-01/#devops-is-the-link-between-the-two","text":"To get to grips with DevOps or the tasks in which a DevOps engineer would be carrying out we need to understand the tools or the process and overview of those and how they come together. Everything starts with the application! You will see so much throughout that it is all about the application when it comes to DevOps. Developers will create an application, this can be done with many different technology stacks and lets leave that to the imagination for now as we get into this later. This can also involve many different programming languages, build tools, code repository etc. As a DevOps engineer you won't be programming the application but having a good understanding of the concepts of how a developer works and the systems, tools and processes they are using is key to success. At a very high level you are going to need to know how the application is configured to talk to all of its required services or data services and then also sprinkle a requirement of how this can or should be tested. The application will need to be deployed somewhere, lets keep it generally simple here and make this a server, doesn't matter where but a server. This is then expected to be accessed by the customer or end user depending on the application that has been created. This server needs to run somewhere, on-premises, in a public cloud, serverless. Someone needs to create and configure these servers and get them ready for the application to run. Now this element might land to you as a DevOps engineer to deploy and configure these servers. These servers will have to run an Operating System and generally speaking this is going to be Linux but we have a whole section or week where we cover some of the foundational knowledge you should gain here. It is also likely that we need to communicate with other services in our network or environment, so we also need to have that level of knowledge around networking and configuring that, this might to some degree also land at the feet of the DevOps engineer. Again we will cover this in more detail in a dedicated section talking all things DNS, DHCP, Load Balancing etc.","title":"DevOps is the link between the two"},{"location":"Week/01/day01-01/#jack-of-all-trades-master-of-none","text":"I will say at this point though, you don't need to be a Network or Infrastructure specialist you need a foundational knowledge of how to get things up and running and talking to each other, much the same as maybe having a foundational knowledge of a programming language but you don't need to be a developer. However you might be coming into this as a specialist in an area and that is a great footing to adapt to other areas. You will also most likely not take over the management of these servers or the application on a daily basis. We have been talking about servers but the likelihood is that your application will be developed to run as containers, Which still runs on a server for the most part but you will also need an understanding of not only virtualisation, Cloud Infrastructure as a Service (IaaS) but also containerization as well, this program will be focused and be catered towards containers.","title":"Jack of all trades, Master of none"},{"location":"Week/01/day01-01/#high-level-overview","text":"On one side we have our developers creating new features and functionality (as well as bug fixes) for the application. On the other side we have some sort of environment, infrastructure or servers which are configured and managed to run this application and communicate with all its required services. The big question is how do we get those features and bug fixes into our production and make it available to those end users? How do we release the new application version? This is one of the main tasks for a DevOps engineer, and the important thing here is not to just figure out how to do this once but we need to do this continuously and in an automated, efficient way which also needs to include testing! This is where we are going to end this day of learning, hopefully this was useful. Over the next few days we are going to dive a little deeper into some more areas of DevOps and then we will get into the sections that dive deeper into the tooling and processes and the benefits of these.","title":"High Level Overview"},{"location":"Week/01/day01-01/#resources","text":"My advice is to watch all of the videos below and take notes on your own textbook or agenda. Going forward, try to keep pen and paper on your side, it will help you whenever you want to go back to your notes in the near future! What is DevOps? - TechWorld with Nana What is DevOps? - GitHub YouTube What is DevOps? - IBM YouTube What is DevOps? - AWS What is DevOps? - Microsoft See you in the Next Section .","title":"Resources"},{"location":"Week/01/day01-02/","text":"DevOps Lifecycle - Application Focused As we continue through these next few weeks we are 100% going to come across these titles (Continuous Development, Testing, Deployment, Monitor) over and over again, If you are heading towards the DevOps Engineer role then repeatability will be something you will get used to but constantly enhancing each time is another thing that keeps things interesting. In this hour we are going to take a look at the high level view of the application from start to finish and then back round again like a constant loop. Development Let's take a brand new example of an Application, to start with we have nothing created, maybe as a developer you have to discuss with your client or end user on the requirements and come up with some sort of plan or requirements for your Application. We then need to create from the requirements our brand new application. In regards to tooling at this stage there is no real requirement here other than choosing your IDE and the programming language you wish to use to write your application. As a DevOps engineer, remember you are probably not the one creating this plan or coding the application for the end user, this will be a skilled developer. But it also would not hurt for you to be able to read some of the code so that you can make the best infrastructure decisions moving forward for your application. We previously mentioned that this application can be written in any language. Importantly this should be maintained using a version control system, this is something we will cover also in detail later on and in particular we will dive into Git . It is also likely that it will not be one developer working on this project although this could be the case but even so best practices would require a code repository to store and collaborate on the code, this could be private or public and could be hosted or privately deployed generally speaking you would hear the likes of GitHub or GitLab being used as a code repository. Again we will cover these as part of our section on Git later on. Testing At this stage we have our requirements and we have our application being developed. But we need to make sure we are testing our code in all the various different environments that we have available to us or specifically maybe to the programming language chosen. This phase enables QA to test for bugs, more frequently we see containers being used for simulating the test environment which overall can improve on cost overheads of physical or cloud infrastructure. This phase is also likely going to be automated as part of the next area which is Continuous Integration. The ability to automate this testing vs 10s,100s or even 1000s of QA engineers having to do this manually speaks for itself, these engineers can focus on something else within the stack to ensure you are moving faster and developing more functionality vs testing bugs and software which tends to be the hold up on most traditional software releases that use a waterfall methodology. Integration Quite importantly Integration is at the middle of the DevOps lifecycle. It is the practice of in which developers require to commit changes to the source code more frequently. This could be on a daily or weekly basis. With every commit your application can go through the automated testing phases and this allows for early detection of issues or bugs before the next phase. Now you might at this stage be saying \"but we don't create applications, we buy it off the shelf from a software vendor\" Don't worry many companies do this and will continue to do this and it will be the software vendor that is concentrating on the above 3 phases but you might want to still adopt the final phase as this will enable for faster and more efficient deployments of your off the shelf deployments. I would also suggest just having this above knowledge is very important as you might buy off the shelf software today, but what about tomorrow or down the line... next job maybe? Deployment Ok so we have our application built and tested against the requirements of our end user and we now need to go ahead and deploy this application into production for our end users to consume. This is the stage where the code is deployed to the production servers, now this is where things get extremely interesting and it is where the rest of our 86 days dives deeper into these areas. Because different applications require different possibly hardware or configurations. This is where Application Configuration Management and Infrastructure as Code could play a key part in your DevOps lifecycle. It might be that your application is Containerised but also available to run on a virtual machine. Which then also leads us onto platforms like Kubernetes which would be orchestrating those containers and making sure you have the desired state available to your end users. All of these bold topics we will go into more detail over the next few weeks to get a better foundational knowledge of what they are and when to use them. Monitoring Things are moving fast here and we have our Application that we are continuously updating with new features and functionality and we have our testing making sure no gremlins are being found. We have the application running in our environment that can be continually keeping the required configuration and performance. But now we need to be sure that our end users are getting the experience they require. Here we need to make sure that our Application Performance is continuously being monitored, this phase is going to allow your developers to make better decisions about enhancements to the application in future releases to better serve the end users. This section is also where we are going to capture that feedback wheel about the features that have been implemented and how the end users would like to make these better for them. Reliability is a key factor here as well, at the end of the day we want our Application to be available all the time it is required. This then lends to other observability, security and data management areas that should be continuously monitored and feedback can always be used to better enhance, update and release the application continuously. Some input from the community here specifically @_ediri mentioned also part of this continous process we should also have the FinOps teams involved. Apps & Data are running and stored somewhere you should be monitoring this continously to make sure if things change from a resources point of view your costs are not causing some major financial pain on your Cloud Bills. I think it is also a good time to bring up the \"DevOps Engineer\" mentions above, albeit there are many DevOps Engineer positions in the wild that people hold, this is not really the ideal way of positioning the process of DevOps. What I mean is from speaking to others in the community the title of DevOps Engineer should not be the goal for anyone because really any position should be adopting DevOps processes and the culture explained here. DevOps should be used in many different positions such as Cloud-Native engineer/architect, virtualisation admin, cloud architect/engineer, infrastructure admin. This is to name a few but the reason for using DevOps Engineer above was really to highlight the scope or the process used by any of the above positions and more. Resources My advice is to watch all of the videos below and take notes on your own textbook or agenda. Going forward, try to keep pen and paper on your side, it will help you whenever you want to go back to your notes in the near future! CI/CD Explained in 100 Seconds - FireShip YouTube Continuous Development I will also add that this is focused on manufacturing but the lean culture can be closely followed with DevOps. Continuous Testing - IBM YouTube Continuous Integration - IBM YouTube Continuous Monitoring The Remote Flow Que es CI/CD - PeladoNerd See you in the Next Section .","title":"2. Application Focused"},{"location":"Week/01/day01-02/#devops-lifecycle-application-focused","text":"As we continue through these next few weeks we are 100% going to come across these titles (Continuous Development, Testing, Deployment, Monitor) over and over again, If you are heading towards the DevOps Engineer role then repeatability will be something you will get used to but constantly enhancing each time is another thing that keeps things interesting. In this hour we are going to take a look at the high level view of the application from start to finish and then back round again like a constant loop.","title":"DevOps Lifecycle - Application Focused"},{"location":"Week/01/day01-02/#development","text":"Let's take a brand new example of an Application, to start with we have nothing created, maybe as a developer you have to discuss with your client or end user on the requirements and come up with some sort of plan or requirements for your Application. We then need to create from the requirements our brand new application. In regards to tooling at this stage there is no real requirement here other than choosing your IDE and the programming language you wish to use to write your application. As a DevOps engineer, remember you are probably not the one creating this plan or coding the application for the end user, this will be a skilled developer. But it also would not hurt for you to be able to read some of the code so that you can make the best infrastructure decisions moving forward for your application. We previously mentioned that this application can be written in any language. Importantly this should be maintained using a version control system, this is something we will cover also in detail later on and in particular we will dive into Git . It is also likely that it will not be one developer working on this project although this could be the case but even so best practices would require a code repository to store and collaborate on the code, this could be private or public and could be hosted or privately deployed generally speaking you would hear the likes of GitHub or GitLab being used as a code repository. Again we will cover these as part of our section on Git later on.","title":"Development"},{"location":"Week/01/day01-02/#testing","text":"At this stage we have our requirements and we have our application being developed. But we need to make sure we are testing our code in all the various different environments that we have available to us or specifically maybe to the programming language chosen. This phase enables QA to test for bugs, more frequently we see containers being used for simulating the test environment which overall can improve on cost overheads of physical or cloud infrastructure. This phase is also likely going to be automated as part of the next area which is Continuous Integration. The ability to automate this testing vs 10s,100s or even 1000s of QA engineers having to do this manually speaks for itself, these engineers can focus on something else within the stack to ensure you are moving faster and developing more functionality vs testing bugs and software which tends to be the hold up on most traditional software releases that use a waterfall methodology.","title":"Testing"},{"location":"Week/01/day01-02/#integration","text":"Quite importantly Integration is at the middle of the DevOps lifecycle. It is the practice of in which developers require to commit changes to the source code more frequently. This could be on a daily or weekly basis. With every commit your application can go through the automated testing phases and this allows for early detection of issues or bugs before the next phase. Now you might at this stage be saying \"but we don't create applications, we buy it off the shelf from a software vendor\" Don't worry many companies do this and will continue to do this and it will be the software vendor that is concentrating on the above 3 phases but you might want to still adopt the final phase as this will enable for faster and more efficient deployments of your off the shelf deployments. I would also suggest just having this above knowledge is very important as you might buy off the shelf software today, but what about tomorrow or down the line... next job maybe?","title":"Integration"},{"location":"Week/01/day01-02/#deployment","text":"Ok so we have our application built and tested against the requirements of our end user and we now need to go ahead and deploy this application into production for our end users to consume. This is the stage where the code is deployed to the production servers, now this is where things get extremely interesting and it is where the rest of our 86 days dives deeper into these areas. Because different applications require different possibly hardware or configurations. This is where Application Configuration Management and Infrastructure as Code could play a key part in your DevOps lifecycle. It might be that your application is Containerised but also available to run on a virtual machine. Which then also leads us onto platforms like Kubernetes which would be orchestrating those containers and making sure you have the desired state available to your end users. All of these bold topics we will go into more detail over the next few weeks to get a better foundational knowledge of what they are and when to use them.","title":"Deployment"},{"location":"Week/01/day01-02/#monitoring","text":"Things are moving fast here and we have our Application that we are continuously updating with new features and functionality and we have our testing making sure no gremlins are being found. We have the application running in our environment that can be continually keeping the required configuration and performance. But now we need to be sure that our end users are getting the experience they require. Here we need to make sure that our Application Performance is continuously being monitored, this phase is going to allow your developers to make better decisions about enhancements to the application in future releases to better serve the end users. This section is also where we are going to capture that feedback wheel about the features that have been implemented and how the end users would like to make these better for them. Reliability is a key factor here as well, at the end of the day we want our Application to be available all the time it is required. This then lends to other observability, security and data management areas that should be continuously monitored and feedback can always be used to better enhance, update and release the application continuously. Some input from the community here specifically @_ediri mentioned also part of this continous process we should also have the FinOps teams involved. Apps & Data are running and stored somewhere you should be monitoring this continously to make sure if things change from a resources point of view your costs are not causing some major financial pain on your Cloud Bills. I think it is also a good time to bring up the \"DevOps Engineer\" mentions above, albeit there are many DevOps Engineer positions in the wild that people hold, this is not really the ideal way of positioning the process of DevOps. What I mean is from speaking to others in the community the title of DevOps Engineer should not be the goal for anyone because really any position should be adopting DevOps processes and the culture explained here. DevOps should be used in many different positions such as Cloud-Native engineer/architect, virtualisation admin, cloud architect/engineer, infrastructure admin. This is to name a few but the reason for using DevOps Engineer above was really to highlight the scope or the process used by any of the above positions and more.","title":"Monitoring"},{"location":"Week/01/day01-02/#resources","text":"My advice is to watch all of the videos below and take notes on your own textbook or agenda. Going forward, try to keep pen and paper on your side, it will help you whenever you want to go back to your notes in the near future! CI/CD Explained in 100 Seconds - FireShip YouTube Continuous Development I will also add that this is focused on manufacturing but the lean culture can be closely followed with DevOps. Continuous Testing - IBM YouTube Continuous Integration - IBM YouTube Continuous Monitoring The Remote Flow Que es CI/CD - PeladoNerd See you in the Next Section .","title":"Resources"},{"location":"Week/01/day01-03/","text":"DevOps & Agile Do you know the difference between DevOps and Agile ? They were formed as standalone concepts. But now the two terms are getting fused. In this post we will examine the crucial differences between agile and DevOps and find out why the two are connected so tightly. I think a good place to start is understanding a little more about a common angle I have seen in learning this area and that is DevOps vs Agile, even though they have similar goals and processes. In this section, I am going to summarise this hopefully. Let's start with definitions. Agile Development Agile is an approach that focuses on delivering small results faster rather than releasing one big interaction of the product, software is developed in iterations. The team releases a new version every week or month with non-incremental updates the final goal of agile is to deliver an optimal experience to the end-users DevOps We have been covering this for the past few days with a few different ways of describing the end goals of DevOps, DevOps usually describes software development and delivery practices based on cooperation between software developers and operations specialists the main DevOps benefits are delivering a simplified development process and minimising miscommunication. What is the difference between Agile and DevOps The difference is mainly the preoccupations. Agile and devops have different preoccupations but they are helping each other. Agile want short iteration, which is only possible with the automation that Devops brings. Agile want customer to try a specific version and quickly give feedback which is only possible if devops make creation of new environment easy. Different participants Agile focuses on optimising communication between end-users and developers while DevOps targets developers and operation team members. We could say that agile is outward-oriented towards customers whereas DevOps is a set of internal practices. Team Agile usually applies to software developers and project managers. The competencies of DevOps engineers lie in the intersection of development, QA and operations they are involved in all stages of the product cycle and they are part of the Agile team. Applied Frameworks Agile has a lot of management frameworks to achieve flexibility and transparency. Scrum > Kanban > Lean > Extreme > Crystal > Dynamic > Feature-Driven >. DevOps focuses on the development approach in collaboration but doesn't offer specific methodologies. However devops promote practices like Infrastructure as Code, Architecture as Code, Monitoring, Self Healing, end to end test automation ... But per say this is not framework, rather practices. Feedback In Agile the main source of feedback is the end user in DevOps the feedback from stakeholders and the team itself has a higher priority. Target areas Agile focuses on software development more than on deployment and maintenance. DevOps focuses on software development as well but its values and tools also cover deployment and post-release stages like monitoring, high availibility, security and data protection. Documentation Agile prioritises flexibility and tasks at hand over documentation and monitor. DevOps on the other hand regards project documentation as one of the essential project components. Risks Agile risks derive from the flexibility of the methodology. Agile projects are difficult to predict or evaluate as priorities and requirements are continually changing. DevOps risks derive from a misunderstanding of the term and the lack of suitable tools. Some people see DevOps as a collection of software for the deployment and continuous integration failing to change the underlying structure of the development process The Tools Used Agile tools are focused on management communication collaboration, metrics and feedback processing. The most popular agile tools include JIRA, Trello, Slack, zoom SurveyMonkey and others. DevOps uses tools for team communication, software development, deployment and integration like Jenkins, GitHub Actions, BitBucket, even though agile and DevOps have slightly different focuses and scopes the key values are almost identical therefore you can combine the two. Bring it all together\u2026 good idea or not? Discuss? The combination of Agile and DevOps brings the following benefits you get - Flexible management and powerful technology - Agile practices help DevOps teams to communicate their priorities more efficiently - The automation cost that you have to pay for your devops practices are justified by your agile requirement of deploying quickly and frequently - It leads to strengthening the team adopting agile practices will improve collaboration increase the team's motivation and decrease employee turnover rates - As a result, you get better product quality Agile allows coming back to previous product development stages to fix errors and prevent the accumulation of technical debt. To adopt agile and DevOps simultaneously just follow 7 steps : Unite the development and operation teams. Create build and run teams, all development and operational concerns are discussed by the entire DevOps team. Change your approach to sprints, assign priority ratings to offer devops tasks that has the same value than development task. Encourage development and operations teams to exchange their opinion on other teams workflow and possible issues. Include QA in all development stages. Choose the right tools. Automate everything you can. Measure and control by using tangible numeric deliverables. What do you think? Do you have different views? I want to hear from you, send me a message on Slack and send me your comments. Resources My advice is to watch all of the videos below and take notes on your own textbook or agenda. Going forward, try to keep pen and paper on your side, it will help you whenever you want to go back to your notes in the near future! DevOps for Developers \u2013 Day in the Life: DevOps Engineer in 2021 3 Things I wish I knew as a DevOps Engineer How to become a DEVOPS Engineer feat. Shawn Powers See you in the Next Section .","title":"3. DevOps & Agile"},{"location":"Week/01/day01-03/#devops-agile","text":"Do you know the difference between DevOps and Agile ? They were formed as standalone concepts. But now the two terms are getting fused. In this post we will examine the crucial differences between agile and DevOps and find out why the two are connected so tightly. I think a good place to start is understanding a little more about a common angle I have seen in learning this area and that is DevOps vs Agile, even though they have similar goals and processes. In this section, I am going to summarise this hopefully. Let's start with definitions.","title":"DevOps &amp; Agile"},{"location":"Week/01/day01-03/#agile-development","text":"Agile is an approach that focuses on delivering small results faster rather than releasing one big interaction of the product, software is developed in iterations. The team releases a new version every week or month with non-incremental updates the final goal of agile is to deliver an optimal experience to the end-users","title":"Agile Development"},{"location":"Week/01/day01-03/#devops","text":"We have been covering this for the past few days with a few different ways of describing the end goals of DevOps, DevOps usually describes software development and delivery practices based on cooperation between software developers and operations specialists the main DevOps benefits are delivering a simplified development process and minimising miscommunication.","title":"DevOps"},{"location":"Week/01/day01-03/#what-is-the-difference-between-agile-and-devops","text":"The difference is mainly the preoccupations. Agile and devops have different preoccupations but they are helping each other. Agile want short iteration, which is only possible with the automation that Devops brings. Agile want customer to try a specific version and quickly give feedback which is only possible if devops make creation of new environment easy.","title":"What is the difference between Agile and DevOps"},{"location":"Week/01/day01-03/#different-participants","text":"Agile focuses on optimising communication between end-users and developers while DevOps targets developers and operation team members. We could say that agile is outward-oriented towards customers whereas DevOps is a set of internal practices.","title":"Different participants"},{"location":"Week/01/day01-03/#team","text":"Agile usually applies to software developers and project managers. The competencies of DevOps engineers lie in the intersection of development, QA and operations they are involved in all stages of the product cycle and they are part of the Agile team.","title":"Team"},{"location":"Week/01/day01-03/#applied-frameworks","text":"Agile has a lot of management frameworks to achieve flexibility and transparency. Scrum > Kanban > Lean > Extreme > Crystal > Dynamic > Feature-Driven >. DevOps focuses on the development approach in collaboration but doesn't offer specific methodologies. However devops promote practices like Infrastructure as Code, Architecture as Code, Monitoring, Self Healing, end to end test automation ... But per say this is not framework, rather practices.","title":"Applied Frameworks"},{"location":"Week/01/day01-03/#feedback","text":"In Agile the main source of feedback is the end user in DevOps the feedback from stakeholders and the team itself has a higher priority.","title":"Feedback"},{"location":"Week/01/day01-03/#target-areas","text":"Agile focuses on software development more than on deployment and maintenance. DevOps focuses on software development as well but its values and tools also cover deployment and post-release stages like monitoring, high availibility, security and data protection.","title":"Target areas"},{"location":"Week/01/day01-03/#documentation","text":"Agile prioritises flexibility and tasks at hand over documentation and monitor. DevOps on the other hand regards project documentation as one of the essential project components.","title":"Documentation"},{"location":"Week/01/day01-03/#risks","text":"Agile risks derive from the flexibility of the methodology. Agile projects are difficult to predict or evaluate as priorities and requirements are continually changing. DevOps risks derive from a misunderstanding of the term and the lack of suitable tools. Some people see DevOps as a collection of software for the deployment and continuous integration failing to change the underlying structure of the development process","title":"Risks"},{"location":"Week/01/day01-03/#the-tools-used","text":"Agile tools are focused on management communication collaboration, metrics and feedback processing. The most popular agile tools include JIRA, Trello, Slack, zoom SurveyMonkey and others. DevOps uses tools for team communication, software development, deployment and integration like Jenkins, GitHub Actions, BitBucket, even though agile and DevOps have slightly different focuses and scopes the key values are almost identical therefore you can combine the two.","title":"The Tools Used"},{"location":"Week/01/day01-03/#bring-it-all-together-good-idea-or-not-discuss","text":"The combination of Agile and DevOps brings the following benefits you get - Flexible management and powerful technology - Agile practices help DevOps teams to communicate their priorities more efficiently - The automation cost that you have to pay for your devops practices are justified by your agile requirement of deploying quickly and frequently - It leads to strengthening the team adopting agile practices will improve collaboration increase the team's motivation and decrease employee turnover rates - As a result, you get better product quality Agile allows coming back to previous product development stages to fix errors and prevent the accumulation of technical debt. To adopt agile and DevOps simultaneously just follow 7 steps : Unite the development and operation teams. Create build and run teams, all development and operational concerns are discussed by the entire DevOps team. Change your approach to sprints, assign priority ratings to offer devops tasks that has the same value than development task. Encourage development and operations teams to exchange their opinion on other teams workflow and possible issues. Include QA in all development stages. Choose the right tools. Automate everything you can. Measure and control by using tangible numeric deliverables. What do you think? Do you have different views? I want to hear from you, send me a message on Slack and send me your comments.","title":"Bring it all together\u2026 good idea or not? Discuss?"},{"location":"Week/01/day01-03/#resources","text":"My advice is to watch all of the videos below and take notes on your own textbook or agenda. Going forward, try to keep pen and paper on your side, it will help you whenever you want to go back to your notes in the near future! DevOps for Developers \u2013 Day in the Life: DevOps Engineer in 2021 3 Things I wish I knew as a DevOps Engineer How to become a DEVOPS Engineer feat. Shawn Powers See you in the Next Section .","title":"Resources"},{"location":"Week/01/day01-04/","text":"Plan > Code > Build > Testing > Release > Deploy > Operate > Monitor > Today we are going to focus on the individual steps from start to finish and the continous cycle of an Application in a DevOps world. Plan: It all starts with the planning process this is where the development team gets together and figure out what types of features and bug fixes that they're going to roll out in their next sprint. This is an opportunity as a DevOps Engineer for you to get involved with that and learn what kinds of things are going to be coming your way that you need to be involved with and also influence their decisions or their path and kind of help them work with the infrastructure that you've built or steer them towards something that's going to work better for them in case they're not on that path and so one key thing to point out here is the developers or software engineering team is your customer as a DevOps engineer so this is your opportunity to work with your customer before they go down a bad path. Code: Now once that planning session's done they're going to go start writing the code you may or may not be involved a whole lot with this one of the places you may get involved with it, is whenever they're writing code you can help them better understand the infrastructure so if they know what services are available and how to best talk with those services so they're going to do that and then once they're done they'll merge that code into the repository Build: This is where we'll kick off the first of our automation processes because we're going to take their code and we're going to build it depending on what language they're using it may be transpiling it or compiling it or it might be creating a docker image from that code either way we're going to go through that process using our ci cd pipeline Testing: Once we've built it we're going to run some tests on it now the development team usually writes the test you may have some input in what tests get written but we need to run those tests and the testing is a way for us to try and minimise introducing problems out into production, it doesn't guarantee that but we want to get as close to a guarantee as we can that were one not introducing new bugs and two not breaking things that used to work Release: Once those tests pass we're going to do the release process and depending again on what type of application you're working on this may be a non-step. You know the code may just live in the GitHub repo or the git repository or wherever it lives but it may be the process of taking your compiled code or the docker image that you've built and putting it into a registry or a repository where it's accessible by your production servers for the deployment process Deploy: which is the thing that we do next because deployment is like the end game of this whole thing because deployments when we put the code into production and it's not until we do that that our business actually realizes the value from all the time effort and hard work that you and the software engineering team have put into this product up to this point. Operate: Once it's deployed we are going to operate it and operate it may involve something like you start getting calls from your customers that they're all annoyed that the site's running slow or their application is running slow right so you need to figure out why that is and then possibly build auto-scaling you know to handle increase the number of servers available during peak periods and decrease the number of servers during off-peak periods either way that's all operational type metrics, another operational thing that you do is include like a feedback loop from production back to your ops team letting you know about key events that happened in production such as a deployment back one step on the deployment thing this may or may not get automated depending on your environment the goal is to always automate it when possible there are some environments where you possibly need to do a few steps before you're ready to do that but ideally you want to deploy automatically as part of your automation process but if you're doing that it might be a good idea to include in your operational steps some type of notification so that your ops team knows that a deployment has happened Monitor: All of the above parts lead to the final step because you need to have monitoring, especially around operational issues auto-scaling troubleshooting like you don't know there's a problem if you don't have monitoring in place to tell you that there's a problem so some of the things you might build monitoring for are memory utilization CPU utilization disk space, api endpoint, response time, how quickly that endpoint is responding and a big part of that as well is logs. Logs give developers the ability to see what is happening without having to access production systems. Rince & Repeat: Once that's in place you go right back to the beginning to the planning stage and go through the whole thing again Continuous: Many tools help us achieve the above continuous process, all this code and the ultimate goal of being completely automated, cloud infrastructure or any environment is often described as Continuous Integration/ Continuous Delivery/Continous Deployment or \u201cCI/CD\u201d for short. We will spend a whole week on CI/CD later on in the 90 Days with some examples and walkthroughs to grasp the fundamentals. Continuous Delivery: Continuous Delivery = Plan > Code > Build > Test Continuous Integration: This is effectively the outcome of the Continuous Delivery phases above plus the outcome of the Release phase. This is the case for both failure and success but this is fed back into continuous delivery or moved to Continuous Deployment. Continuous Integration = Plan > Code > Build > Test > Release Continuous Deployment: If you have a successful release from your continuous integration then move to Continuous Deployment which brings in the following phases CI Release is Success = Continuous Deployment = Deploy > Operate > Monitor You can see these three Continuous notions above as the simple collection of phases of the DevOps Lifecycle. This last bit was a bit of a recap for me on Day 3 but think this actually makes things clearer for me. Resources: My advice is to watch all of the videos below and take notes on your own textbook or agenda. Going forward, try to keep pen and paper on your side, it will help you whenever you want to go back to your notes in the near future! DevOps for Developers \u2013 Software or DevOps Engineer? Techworld with Nana -DevOps Roadmap 2022 - How to become a DevOps Engineer? What is DevOps? How to become a DevOps Engineer in 2021 - DevOps Roadmap See you in the Next Section .","title":"4. DevOps Cycle"},{"location":"Week/01/day01-04/#plan-code-build-testing-release-deploy-operate-monitor","text":"Today we are going to focus on the individual steps from start to finish and the continous cycle of an Application in a DevOps world.","title":"Plan &gt; Code &gt; Build &gt; Testing &gt; Release &gt; Deploy &gt; Operate &gt; Monitor &gt;"},{"location":"Week/01/day01-04/#plan","text":"It all starts with the planning process this is where the development team gets together and figure out what types of features and bug fixes that they're going to roll out in their next sprint. This is an opportunity as a DevOps Engineer for you to get involved with that and learn what kinds of things are going to be coming your way that you need to be involved with and also influence their decisions or their path and kind of help them work with the infrastructure that you've built or steer them towards something that's going to work better for them in case they're not on that path and so one key thing to point out here is the developers or software engineering team is your customer as a DevOps engineer so this is your opportunity to work with your customer before they go down a bad path.","title":"Plan:"},{"location":"Week/01/day01-04/#code","text":"Now once that planning session's done they're going to go start writing the code you may or may not be involved a whole lot with this one of the places you may get involved with it, is whenever they're writing code you can help them better understand the infrastructure so if they know what services are available and how to best talk with those services so they're going to do that and then once they're done they'll merge that code into the repository","title":"Code:"},{"location":"Week/01/day01-04/#build","text":"This is where we'll kick off the first of our automation processes because we're going to take their code and we're going to build it depending on what language they're using it may be transpiling it or compiling it or it might be creating a docker image from that code either way we're going to go through that process using our ci cd pipeline","title":"Build:"},{"location":"Week/01/day01-04/#testing","text":"Once we've built it we're going to run some tests on it now the development team usually writes the test you may have some input in what tests get written but we need to run those tests and the testing is a way for us to try and minimise introducing problems out into production, it doesn't guarantee that but we want to get as close to a guarantee as we can that were one not introducing new bugs and two not breaking things that used to work","title":"Testing:"},{"location":"Week/01/day01-04/#release","text":"Once those tests pass we're going to do the release process and depending again on what type of application you're working on this may be a non-step. You know the code may just live in the GitHub repo or the git repository or wherever it lives but it may be the process of taking your compiled code or the docker image that you've built and putting it into a registry or a repository where it's accessible by your production servers for the deployment process","title":"Release:"},{"location":"Week/01/day01-04/#deploy","text":"which is the thing that we do next because deployment is like the end game of this whole thing because deployments when we put the code into production and it's not until we do that that our business actually realizes the value from all the time effort and hard work that you and the software engineering team have put into this product up to this point.","title":"Deploy:"},{"location":"Week/01/day01-04/#operate","text":"Once it's deployed we are going to operate it and operate it may involve something like you start getting calls from your customers that they're all annoyed that the site's running slow or their application is running slow right so you need to figure out why that is and then possibly build auto-scaling you know to handle increase the number of servers available during peak periods and decrease the number of servers during off-peak periods either way that's all operational type metrics, another operational thing that you do is include like a feedback loop from production back to your ops team letting you know about key events that happened in production such as a deployment back one step on the deployment thing this may or may not get automated depending on your environment the goal is to always automate it when possible there are some environments where you possibly need to do a few steps before you're ready to do that but ideally you want to deploy automatically as part of your automation process but if you're doing that it might be a good idea to include in your operational steps some type of notification so that your ops team knows that a deployment has happened","title":"Operate:"},{"location":"Week/01/day01-04/#monitor","text":"All of the above parts lead to the final step because you need to have monitoring, especially around operational issues auto-scaling troubleshooting like you don't know there's a problem if you don't have monitoring in place to tell you that there's a problem so some of the things you might build monitoring for are memory utilization CPU utilization disk space, api endpoint, response time, how quickly that endpoint is responding and a big part of that as well is logs. Logs give developers the ability to see what is happening without having to access production systems.","title":"Monitor:"},{"location":"Week/01/day01-04/#rince-repeat","text":"Once that's in place you go right back to the beginning to the planning stage and go through the whole thing again","title":"Rince &amp; Repeat:"},{"location":"Week/01/day01-04/#continuous","text":"Many tools help us achieve the above continuous process, all this code and the ultimate goal of being completely automated, cloud infrastructure or any environment is often described as Continuous Integration/ Continuous Delivery/Continous Deployment or \u201cCI/CD\u201d for short. We will spend a whole week on CI/CD later on in the 90 Days with some examples and walkthroughs to grasp the fundamentals.","title":"Continuous:"},{"location":"Week/01/day01-04/#continuous-delivery","text":"Continuous Delivery = Plan > Code > Build > Test","title":"Continuous Delivery:"},{"location":"Week/01/day01-04/#continuous-integration","text":"This is effectively the outcome of the Continuous Delivery phases above plus the outcome of the Release phase. This is the case for both failure and success but this is fed back into continuous delivery or moved to Continuous Deployment. Continuous Integration = Plan > Code > Build > Test > Release","title":"Continuous Integration:"},{"location":"Week/01/day01-04/#continuous-deployment","text":"If you have a successful release from your continuous integration then move to Continuous Deployment which brings in the following phases CI Release is Success = Continuous Deployment = Deploy > Operate > Monitor You can see these three Continuous notions above as the simple collection of phases of the DevOps Lifecycle. This last bit was a bit of a recap for me on Day 3 but think this actually makes things clearer for me.","title":"Continuous Deployment:"},{"location":"Week/01/day01-04/#resources","text":"My advice is to watch all of the videos below and take notes on your own textbook or agenda. Going forward, try to keep pen and paper on your side, it will help you whenever you want to go back to your notes in the near future! DevOps for Developers \u2013 Software or DevOps Engineer? Techworld with Nana -DevOps Roadmap 2022 - How to become a DevOps Engineer? What is DevOps? How to become a DevOps Engineer in 2021 - DevOps Roadmap See you in the Next Section .","title":"Resources:"},{"location":"Week/01/day01-05/","text":"DevOps - The real stories DevOps to begin with was seen to be out of reach for a lot of us as we didn't have an environment or requirement anything like a Netflix or fortune 500 but think now that is beginning to sway into the normal when adopting a DevOps practice within any type of business. You will see from the second link below in references there are a lot of different industries and verticals using DevOps and having a hugely positive effect on their business objectives. Obviously the overarching benefit here is DevOps if done correctly should help your Business improve the speed and quality of software development. I wanted to take this section to look at succesful companies that have adopted a DevOps practice and share some resources around this. I mentioned Netflix above and will touch on them again as it is a very good model and advanced to what we generally see today even still but will also mention some other big name brands that are succeeding it seems. Amazon In 2010 Amazon moved their physical server footprint to Amazon Web Services (AWS) cloud this allowed them to save resources by scaling capacity up and down in very small increments. We also know that this AWS cloud would go on and make a huge amount of revenue itself whilst still running the Amazon retail branch of the company. Amazon adopted in 2011 (According to the resource below) a continued deployment process where their developers could deploy code whenever they want and to whatever servers they needed. This enabled Amazon to achieve deploying new software to production servers on average every 11.6 seconds! Netflix Who doesn't use Netflix? obviously a huge quality streaming service with by all accounts at least personally a great user experience. Why is that user experience so great? Well the ability to deliver a service with no recollected memory for me at least of glitches requires speed, flexibility, and attention to quality. NetFlix developers can automatically build pieces of code into deployable web images without relying on IT operations. As the images are updated, they are integrated into Netflix\u2019s infrastructure using a custom-built, web-based platform. Continous Monitoring is in place so that if the deployment of the images fails, the new images are rolled back and traffic rerouted to the previous version. There is a great talk listed below that goes into more about the DOs and DONTs that Netflix live and die by within their teams. Etsy As with many of us and many companies there was a real struggle around slow and painful deployments. In the same vein we might have also experienced working in companies that have lots of siloes and teams that are not really working well together. From what I can make out at least from reading about Amazon and Netflix, Etsy might have adopted the letting developers deploy their own code around the end of 2009 which might have been before the other two mentioned. (interesting!) An interesting take away I read here was that they realised that when developers feel responsibility for deployment they also would take responsibility for application performance, uptime and other goals. A learning culture is a key part to DevOps, even failure can be a success if lessons are learned. (not sure where this quote actually came from but it kind of makes sense!) I have added some other stories where DevOps has changed the game within some of these massively successful companies. Resources My advice is to watch all of the videos below and take notes on your own textbook or agenda. Going forward, try to keep pen and paper on your side, it will help you whenever you want to go back to your notes in the near future! How Netflix Thinks of DevOps 16 Popular DevOps Use Cases & Real Life Applications [2021] DevOps: The Amazon Story How Etsy makes DevOps work Adopting DevOps @ Scale Lessons learned at Hertz, Kaiser Permanente and lBM Interplanetary DevOps at NASA JPL Target CIO explains how DevOps took root inside the retail giant Recap of our first week looking at DevOps DevOps is a combo of Development and Operations that allows a single team to manage the whole application development lifecycle that consists of Development , Testing , Deployment , Operations . The main focus and aim of DevOps is to shorten the development lifecycle while delivering features, fixes and functionality frequently in close alignment with business objectives. DevOps is a software development approach through which software can be delivered and developed reliably and quickly. You may also see this referenced as Continuous Development, Testing, Deployment, Monitoring See you in Next Section . Next we will dive into a programming language. We are not aiming to be a web developer per say but we want to be able to understand what the developers are doing.","title":"5. The real stories"},{"location":"Week/01/day01-05/#devops-the-real-stories","text":"DevOps to begin with was seen to be out of reach for a lot of us as we didn't have an environment or requirement anything like a Netflix or fortune 500 but think now that is beginning to sway into the normal when adopting a DevOps practice within any type of business. You will see from the second link below in references there are a lot of different industries and verticals using DevOps and having a hugely positive effect on their business objectives. Obviously the overarching benefit here is DevOps if done correctly should help your Business improve the speed and quality of software development. I wanted to take this section to look at succesful companies that have adopted a DevOps practice and share some resources around this. I mentioned Netflix above and will touch on them again as it is a very good model and advanced to what we generally see today even still but will also mention some other big name brands that are succeeding it seems.","title":"DevOps - The real stories"},{"location":"Week/01/day01-05/#amazon","text":"In 2010 Amazon moved their physical server footprint to Amazon Web Services (AWS) cloud this allowed them to save resources by scaling capacity up and down in very small increments. We also know that this AWS cloud would go on and make a huge amount of revenue itself whilst still running the Amazon retail branch of the company. Amazon adopted in 2011 (According to the resource below) a continued deployment process where their developers could deploy code whenever they want and to whatever servers they needed. This enabled Amazon to achieve deploying new software to production servers on average every 11.6 seconds!","title":"Amazon"},{"location":"Week/01/day01-05/#netflix","text":"Who doesn't use Netflix? obviously a huge quality streaming service with by all accounts at least personally a great user experience. Why is that user experience so great? Well the ability to deliver a service with no recollected memory for me at least of glitches requires speed, flexibility, and attention to quality. NetFlix developers can automatically build pieces of code into deployable web images without relying on IT operations. As the images are updated, they are integrated into Netflix\u2019s infrastructure using a custom-built, web-based platform. Continous Monitoring is in place so that if the deployment of the images fails, the new images are rolled back and traffic rerouted to the previous version. There is a great talk listed below that goes into more about the DOs and DONTs that Netflix live and die by within their teams.","title":"Netflix"},{"location":"Week/01/day01-05/#etsy","text":"As with many of us and many companies there was a real struggle around slow and painful deployments. In the same vein we might have also experienced working in companies that have lots of siloes and teams that are not really working well together. From what I can make out at least from reading about Amazon and Netflix, Etsy might have adopted the letting developers deploy their own code around the end of 2009 which might have been before the other two mentioned. (interesting!) An interesting take away I read here was that they realised that when developers feel responsibility for deployment they also would take responsibility for application performance, uptime and other goals. A learning culture is a key part to DevOps, even failure can be a success if lessons are learned. (not sure where this quote actually came from but it kind of makes sense!) I have added some other stories where DevOps has changed the game within some of these massively successful companies.","title":"Etsy"},{"location":"Week/01/day01-05/#resources","text":"My advice is to watch all of the videos below and take notes on your own textbook or agenda. Going forward, try to keep pen and paper on your side, it will help you whenever you want to go back to your notes in the near future! How Netflix Thinks of DevOps 16 Popular DevOps Use Cases & Real Life Applications [2021] DevOps: The Amazon Story How Etsy makes DevOps work Adopting DevOps @ Scale Lessons learned at Hertz, Kaiser Permanente and lBM Interplanetary DevOps at NASA JPL Target CIO explains how DevOps took root inside the retail giant","title":"Resources"},{"location":"Week/01/day01-05/#recap-of-our-first-week-looking-at-devops","text":"DevOps is a combo of Development and Operations that allows a single team to manage the whole application development lifecycle that consists of Development , Testing , Deployment , Operations . The main focus and aim of DevOps is to shorten the development lifecycle while delivering features, fixes and functionality frequently in close alignment with business objectives. DevOps is a software development approach through which software can be delivered and developed reliably and quickly. You may also see this referenced as Continuous Development, Testing, Deployment, Monitoring See you in Next Section . Next we will dive into a programming language. We are not aiming to be a web developer per say but we want to be able to understand what the developers are doing.","title":"Recap of our first week looking at DevOps"},{"location":"Week/01/day02-01/","text":"The Big Picture: DevOps & Learning a Programming Language It is important to highlight that to be successful in the long term as a DevOps engineer, you've got to know at least one programming language at a foundational level. We want to take this first session of this section to explore why this is such a critical skill to have, and hopefully, by the end of this week or section, you are going to have a better understanding of the why, how and what to do to progress with your learning journey. If we were to ask out on the wild if you need to have programming skills for DevOps related roles, the answer would probably be a resounding yes. However, the bigger question here that most of us ask ourselves is which programming language should I invest my time into? The most common answer in 2022 has been Python or increasingly more often, we're seeing Golang or Go as one of the best languages that you can learn for this role. To be successful in DevOps you have to have a good knowledge of programming skills but further than that, what is value in the role is the ability to solve problems as much as proposing architectural designs and solutions for scalable applications in the cloud. Understand why you need to learn a programming language. The reason that Python and Go are recommended so often for DevOps engineers is that a lot of the DevOps tooling is written in either Python or Go, which makes sense if you are going to be building, using and maintaing any type of DevOps tools. Now this is important as this will determine really what you should learn and that would likely be the most beneficial skillsets for this career path. Since in the future, we are going to be heavily involved in Kubernetes and Containers, then it's more than likely that choosing Go as your programming language would heavily increase productivity but Python will be as helpful for you. In our ecosystems, we are focusing on deploying EC2 instances on AWS and automating a lot of our tasks and deployments using Terraform so having knowledge on data management for Kubernetes will be beneficial as everything is written in Go. Remember we are not going to be building applications but the goal here is to understand a little more about the programming language so that we can read and understand what those tools are doing and then that can bring opportunities on how we can help on improving our tools. I would also it is also important to know how you interact with those DevOps tools which could be K8s or it could be Terraform and Ansible. These are what we will call config files and this is how you interact with those DevOps tools to make things happen, commonly these are going to be YAML. (We may use the last day of this section to dive a little into YAML) Did we just talk ourselves out of learning a programming language? Most of the time or depending on the role, you will be helping engineering teams implement DevOps into their workflow, a lot of testing around the application and making sure that the workflow that is built aligns to those DevOps principles we mentioned over the first few days. But in reality, this is going to be a lot of the time troubleshooting an application performance issue or something along those lines. This comes back to my original point and reasoning, the programming language I need to know is the one that the code is written in? If their application is written in NodeJS it won\u2019t help much if you have a Go or Python badge or certification. Why Go You may ask yourself why is Golangv considered as the next programming language for DevOps and you may find that most Go most definitely has become a very popular programming language in recent years. According to the StackOverflow Survey for 2021, Go came in fourth for the most wanted Programming, scripting and markup languages with Python being top. StackOverflow 2021 Developer Survey \u2013 Most Wanted Link However, as I have also mentioned some of the most known DevOps tools and platforms are written in Go such as Kubernetes, Docker, Grafana and Prometheus and having at least a base knowledge on Go will greatly elevate your understanding when working with those type of tools. What are some of the characteristics of Go that make it great for DevOps? Build and Deployment of Go Programs An advantage of using a language like Python that is interpreted in a DevOps role is that you don\u2019t need to compile a python program before running it. Especially for smaller automation tasks, you don\u2019t want to be slowed down by a build process that requires compilation even though, Go is a compiled programming language, Go compiles directly into machine code . Go is known also for fast compilation times. Go vs Python for DevOps Go Programs are statically linked, this means that when you compile a go program everything is included in a single binary executable, no external dependencies will be required that would need to be installed on the remote machine, this makes the deployment of go programs easy, compared to python program that uses external libraries you have to make sure that all those libraries are installed on the remote machine that you wish to run on. Go is a platform-independent language, which means you can produce binary executables for *all the operating systems, Linux, Windows, macOS etc and very easy to do so. With Python, it is not as easy to create these binary executables for particular operating systems. Go is a very performant language, it has fast compilation and fast run time with lower resource usage like CPU and memory especially compared to python, numerous optimizations have been implemented in the Go language that makes it so performant. (Resources below) Unlike Python which often requires the use of third party libraries to implement a particular python program, go includes a standard library that has the majority of functionality that you would need for DevOps built directly into it. This includes functionality file processing, HTTP web services, JSON processing, native support for concurrency and parallelism as well as built-in testing. This is by no way throwing Python under the bus as we will still be touching and seeing python further down the course, however the main reasoning here for choosing Go just right now is so that we can have a broader knowledge on how Go applications are constructed, however in the future you can easiy focus on Python if that's your cup of tea and that's completely valid. Just that for now, we will work with Go just to build general bases on it which will prove to be helpful whenever we work with devops tools that are programmed on this specific language. I will say that once you start fo fully master a programming language it becomes easier to take on other languages. You're probably never going to have a single job in any company anywhere where you don't have to deal with manage, architect, orchestrating, debug JavaScript and Node JS applications so being able to be versatile with our skills will definitely set us up for success. Resources StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Now for the next 6 days of this topic my intention is to work through some of the resources listed above and document your notes for each day. You will notice that they are generally around 3 hours as a full course, I wanted to share my complete list so that if you have time you should move ahead and work through each one if time permits. I am not expecting that we will learn a programming language from beginning to end within a week but will definitely be a great tool to start using on our workflows. See you in Next Section .","title":"1. The Big Picture: Learning a Programming Language"},{"location":"Week/01/day02-01/#the-big-picture-devops-learning-a-programming-language","text":"It is important to highlight that to be successful in the long term as a DevOps engineer, you've got to know at least one programming language at a foundational level. We want to take this first session of this section to explore why this is such a critical skill to have, and hopefully, by the end of this week or section, you are going to have a better understanding of the why, how and what to do to progress with your learning journey. If we were to ask out on the wild if you need to have programming skills for DevOps related roles, the answer would probably be a resounding yes. However, the bigger question here that most of us ask ourselves is which programming language should I invest my time into? The most common answer in 2022 has been Python or increasingly more often, we're seeing Golang or Go as one of the best languages that you can learn for this role. To be successful in DevOps you have to have a good knowledge of programming skills but further than that, what is value in the role is the ability to solve problems as much as proposing architectural designs and solutions for scalable applications in the cloud.","title":"The Big Picture: DevOps &amp; Learning a Programming Language"},{"location":"Week/01/day02-01/#understand-why-you-need-to-learn-a-programming-language","text":"The reason that Python and Go are recommended so often for DevOps engineers is that a lot of the DevOps tooling is written in either Python or Go, which makes sense if you are going to be building, using and maintaing any type of DevOps tools. Now this is important as this will determine really what you should learn and that would likely be the most beneficial skillsets for this career path. Since in the future, we are going to be heavily involved in Kubernetes and Containers, then it's more than likely that choosing Go as your programming language would heavily increase productivity but Python will be as helpful for you. In our ecosystems, we are focusing on deploying EC2 instances on AWS and automating a lot of our tasks and deployments using Terraform so having knowledge on data management for Kubernetes will be beneficial as everything is written in Go. Remember we are not going to be building applications but the goal here is to understand a little more about the programming language so that we can read and understand what those tools are doing and then that can bring opportunities on how we can help on improving our tools. I would also it is also important to know how you interact with those DevOps tools which could be K8s or it could be Terraform and Ansible. These are what we will call config files and this is how you interact with those DevOps tools to make things happen, commonly these are going to be YAML. (We may use the last day of this section to dive a little into YAML)","title":"Understand why you need to learn a programming language."},{"location":"Week/01/day02-01/#did-we-just-talk-ourselves-out-of-learning-a-programming-language","text":"Most of the time or depending on the role, you will be helping engineering teams implement DevOps into their workflow, a lot of testing around the application and making sure that the workflow that is built aligns to those DevOps principles we mentioned over the first few days. But in reality, this is going to be a lot of the time troubleshooting an application performance issue or something along those lines. This comes back to my original point and reasoning, the programming language I need to know is the one that the code is written in? If their application is written in NodeJS it won\u2019t help much if you have a Go or Python badge or certification.","title":"Did we just talk ourselves out of learning a programming language?"},{"location":"Week/01/day02-01/#why-go","text":"You may ask yourself why is Golangv considered as the next programming language for DevOps and you may find that most Go most definitely has become a very popular programming language in recent years. According to the StackOverflow Survey for 2021, Go came in fourth for the most wanted Programming, scripting and markup languages with Python being top. StackOverflow 2021 Developer Survey \u2013 Most Wanted Link However, as I have also mentioned some of the most known DevOps tools and platforms are written in Go such as Kubernetes, Docker, Grafana and Prometheus and having at least a base knowledge on Go will greatly elevate your understanding when working with those type of tools. What are some of the characteristics of Go that make it great for DevOps?","title":"Why Go"},{"location":"Week/01/day02-01/#build-and-deployment-of-go-programs","text":"An advantage of using a language like Python that is interpreted in a DevOps role is that you don\u2019t need to compile a python program before running it. Especially for smaller automation tasks, you don\u2019t want to be slowed down by a build process that requires compilation even though, Go is a compiled programming language, Go compiles directly into machine code . Go is known also for fast compilation times.","title":"Build and Deployment of Go Programs"},{"location":"Week/01/day02-01/#go-vs-python-for-devops","text":"Go Programs are statically linked, this means that when you compile a go program everything is included in a single binary executable, no external dependencies will be required that would need to be installed on the remote machine, this makes the deployment of go programs easy, compared to python program that uses external libraries you have to make sure that all those libraries are installed on the remote machine that you wish to run on. Go is a platform-independent language, which means you can produce binary executables for *all the operating systems, Linux, Windows, macOS etc and very easy to do so. With Python, it is not as easy to create these binary executables for particular operating systems. Go is a very performant language, it has fast compilation and fast run time with lower resource usage like CPU and memory especially compared to python, numerous optimizations have been implemented in the Go language that makes it so performant. (Resources below) Unlike Python which often requires the use of third party libraries to implement a particular python program, go includes a standard library that has the majority of functionality that you would need for DevOps built directly into it. This includes functionality file processing, HTTP web services, JSON processing, native support for concurrency and parallelism as well as built-in testing. This is by no way throwing Python under the bus as we will still be touching and seeing python further down the course, however the main reasoning here for choosing Go just right now is so that we can have a broader knowledge on how Go applications are constructed, however in the future you can easiy focus on Python if that's your cup of tea and that's completely valid. Just that for now, we will work with Go just to build general bases on it which will prove to be helpful whenever we work with devops tools that are programmed on this specific language. I will say that once you start fo fully master a programming language it becomes easier to take on other languages. You're probably never going to have a single job in any company anywhere where you don't have to deal with manage, architect, orchestrating, debug JavaScript and Node JS applications so being able to be versatile with our skills will definitely set us up for success.","title":"Go vs Python for DevOps"},{"location":"Week/01/day02-01/#resources","text":"StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist Now for the next 6 days of this topic my intention is to work through some of the resources listed above and document your notes for each day. You will notice that they are generally around 3 hours as a full course, I wanted to share my complete list so that if you have time you should move ahead and work through each one if time permits. I am not expecting that we will learn a programming language from beginning to end within a week but will definitely be a great tool to start using on our workflows. See you in Next Section .","title":"Resources"},{"location":"Week/01/day02-02/","text":"Setting up your DevOps environment for Go & Hello World Before we get into some of the fundamentals of Go we should get Go installed on our workstation and do what every \"learning programming 101\" module teaches us which is to create the Hello World app. As this one is going to be walking through the steps to get Go installed on your workstation we are going to attempt to document the process in pictures so it is can be easily followed along. First of all, let's head on over to go.dev/dl and you will be greeted with some available options for downloads. You probably know which workstation operating system you are running so select the appropriate download and then we can start the installation process. I am using MacOS for this walkthrough, basically, from this next screen, we can leave all the defaults in place for now. (I will note that at the time of writing this was the latest version so screenshots might be out of date) Also note if you do have an older version of Go installed you will have to remove this before installing, Windows has this built into the installer and will remove and install as one. Once finished you should now open a command prompt/terminal and we want to check that we have Go installed. If you do not get the output that we see below then Go is not installed and you will need to retrace your steps. go version Next up we want to check our environment for Go. This is always good to check to make sure your working directories are configured correctly, as you can see below we need to make sure you have the following directory on your system. Did you check? Are you following along? You will probably get something like the below if you try and navigate there. Ok, let's create that directory for ease I am going to use the mkdir command through terminal. We also need to create 3 folders within the Go folder as you will see also below. Now we have Go installed and we have our Go working directory ready for action. We now need an integrated development environment (IDE). Now there are many out there available that you can use but the most common and the one I use is Visual Studio Code or Code. You can learn more about IDEs here . If you have not downloaded and installed VSCode already on your workstation then you can do so by heading here . As you can see below you have your different OS options. Much the same as with the Go installation we are going to download and install and keep the defaults. Once complete you can open VSCode and you can select Open File and navigate to our Go directory that we created above. You may get a popup about trust, read it if you want and then hit Yes, trust the authors. Now you should see the three folders we also created earlier as well and what we want to do now is right click the src folder and create a new folder called Hello Pretty easy stuff I would say up till this point? Now we are going to create our first Go Program with no understanding about anything we put in this next phase. Next create a file called main.go in your hello folder. As soon as you hit enter on the main.go you will be asked if you want to install the Go extension. Go ahead and install those as it will package additional files for you. Once it is done installing, you'll be able to check that the empty pkg file that we made a few steps back now has some new packages inside it: Now let's get this Hello World app going, copy for the following code into your new main.go file and save that. package main import \"fmt\" func main() { fmt.Println(\"Hello #DevOpsTraineeProgram\") } Now lets appreciate that the above might make no sense at all, but we will cover more about functions, packages and more in later days. For now let's run our app. Back in the terminal and in our Hello folder we can now check that all is working. Using the command below we can check to see if our generic learning program is working. go run main.go It doesn't end there though, what if we now want to take our program and run it on other MacOS machines? We can do that by building our binary using the following command go build main.go If we execute this file with ./main instead of go run main as you'll get the following message if you do package main is not in GOROOT See you on Next Section .","title":"2. Setting up your DevOps environment for Go & Hello World"},{"location":"Week/01/day02-02/#setting-up-your-devops-environment-for-go-hello-world","text":"Before we get into some of the fundamentals of Go we should get Go installed on our workstation and do what every \"learning programming 101\" module teaches us which is to create the Hello World app. As this one is going to be walking through the steps to get Go installed on your workstation we are going to attempt to document the process in pictures so it is can be easily followed along. First of all, let's head on over to go.dev/dl and you will be greeted with some available options for downloads. You probably know which workstation operating system you are running so select the appropriate download and then we can start the installation process. I am using MacOS for this walkthrough, basically, from this next screen, we can leave all the defaults in place for now. (I will note that at the time of writing this was the latest version so screenshots might be out of date) Also note if you do have an older version of Go installed you will have to remove this before installing, Windows has this built into the installer and will remove and install as one. Once finished you should now open a command prompt/terminal and we want to check that we have Go installed. If you do not get the output that we see below then Go is not installed and you will need to retrace your steps. go version Next up we want to check our environment for Go. This is always good to check to make sure your working directories are configured correctly, as you can see below we need to make sure you have the following directory on your system. Did you check? Are you following along? You will probably get something like the below if you try and navigate there. Ok, let's create that directory for ease I am going to use the mkdir command through terminal. We also need to create 3 folders within the Go folder as you will see also below. Now we have Go installed and we have our Go working directory ready for action. We now need an integrated development environment (IDE). Now there are many out there available that you can use but the most common and the one I use is Visual Studio Code or Code. You can learn more about IDEs here . If you have not downloaded and installed VSCode already on your workstation then you can do so by heading here . As you can see below you have your different OS options. Much the same as with the Go installation we are going to download and install and keep the defaults. Once complete you can open VSCode and you can select Open File and navigate to our Go directory that we created above. You may get a popup about trust, read it if you want and then hit Yes, trust the authors. Now you should see the three folders we also created earlier as well and what we want to do now is right click the src folder and create a new folder called Hello Pretty easy stuff I would say up till this point? Now we are going to create our first Go Program with no understanding about anything we put in this next phase. Next create a file called main.go in your hello folder. As soon as you hit enter on the main.go you will be asked if you want to install the Go extension. Go ahead and install those as it will package additional files for you. Once it is done installing, you'll be able to check that the empty pkg file that we made a few steps back now has some new packages inside it: Now let's get this Hello World app going, copy for the following code into your new main.go file and save that. package main import \"fmt\" func main() { fmt.Println(\"Hello #DevOpsTraineeProgram\") } Now lets appreciate that the above might make no sense at all, but we will cover more about functions, packages and more in later days. For now let's run our app. Back in the terminal and in our Hello folder we can now check that all is working. Using the command below we can check to see if our generic learning program is working. go run main.go It doesn't end there though, what if we now want to take our program and run it on other MacOS machines? We can do that by building our binary using the following command go build main.go If we execute this file with ./main instead of go run main as you'll get the following message if you do package main is not in GOROOT See you on Next Section .","title":"Setting up your DevOps environment for Go &amp; Hello World"},{"location":"Week/01/day02-03/","text":"Let's explain the Hello World code How Go works On the Previous Section we walked through getting Go installed on your workstation and we then created our first Go application. In this section, we are going to take a deeper look into the code and understand a few more things about the Go language. What is Compiling? Before we get into the 6 lines of the Hello World code we need to have a bit of an understanding about compiling. Programming languages that we commonly use such as Python, Java, Go and C++ are high-level languages. Meaning they are human-readable but when a machine is trying to execute a program it needs to be in a form that a machine can understand. We have to translate our human-readable code to machine code which is called compiling. From the above you can see what we did on Previous Section here, we created a simple Hello World main.go and we then used the command go build main.go to compile our executable. What are packages? A package is a collection of source files in the same directory that are compiled together. We can simplify this further, a package is a bunch of .go files in the same directory. Remember our Hello folder from Day 8? If and when you get into more complex Go programs you might find that you have folder1 folder2 and folder3 containing different .go files that make up your program with multiple packages. We use packages so we can reuse other peoples code, we don't have to write everything from scratch. Maybe we are wanting a calculator as part of our program, you could probably find an existing Go Package that contains the mathematical functions that you could import into your code saving you a lot of time and effort in the long run. Go encourages you to organise your code in packages so that it is easy to reuse and maintain source code. Hello #DevOpsTraineeProgram Line by Line Now let's take a look at our Hello #DevOpsTraineeProgram main.go file and walk through the lines. In the first line, you have package main which means that this file belongs to a package called main. All .go files need to belong to a package, they should also have package something in the opening line. A package can be named whatever you wish. We have to call this main as this is the starting point of the program that is going to be in this package, this is a rule. (Feel free to further research to understand more regarding this rule.) Whenever we want to compile and execute our code we have to tell the machine where the execution needs to start. We do this by writing a function called main. The machine will look for a function called main to find the entry point of the program. A function is a block of code that can do some specific task for and can be used across the program. You can declare a function with any name using func but in this case we need to name it main as this is where the code starts. Next we are going to look at line 3 of our code, the import, this basically means you want to bring in another package to your main program. fmt is a standard package being used here provided by Go, this package contains the Println() function and because we have imported this we can use this in line 6. There are a number of standard packages you can include in your program and leverage or reuse them in your code saving you the hassle of having to write from scratch. Go Standard Library the Println() that we have here is a way in which to write to a standard output to the terminal whenever the executuable has been executed succesfully. Feel free to change the message in between the () . TLDR Line 1 = This file will be in the package called main and this needs to be called main because includes the entry point of the program. Line 3 = For us to be able to use the Println() function, we have to import the fmt package to use this on line 6. Line 5 = The actual starting point, its the main function. Line 6 = This will let us print \"Hello #DevOpsTraineeProgram\" on our system. See you on Next Section .","title":"3. Let's explain the Hello World code"},{"location":"Week/01/day02-03/#lets-explain-the-hello-world-code","text":"","title":"Let's explain the Hello World code"},{"location":"Week/01/day02-03/#how-go-works","text":"On the Previous Section we walked through getting Go installed on your workstation and we then created our first Go application. In this section, we are going to take a deeper look into the code and understand a few more things about the Go language.","title":"How Go works"},{"location":"Week/01/day02-03/#what-is-compiling","text":"Before we get into the 6 lines of the Hello World code we need to have a bit of an understanding about compiling. Programming languages that we commonly use such as Python, Java, Go and C++ are high-level languages. Meaning they are human-readable but when a machine is trying to execute a program it needs to be in a form that a machine can understand. We have to translate our human-readable code to machine code which is called compiling. From the above you can see what we did on Previous Section here, we created a simple Hello World main.go and we then used the command go build main.go to compile our executable.","title":"What is Compiling?"},{"location":"Week/01/day02-03/#what-are-packages","text":"A package is a collection of source files in the same directory that are compiled together. We can simplify this further, a package is a bunch of .go files in the same directory. Remember our Hello folder from Day 8? If and when you get into more complex Go programs you might find that you have folder1 folder2 and folder3 containing different .go files that make up your program with multiple packages. We use packages so we can reuse other peoples code, we don't have to write everything from scratch. Maybe we are wanting a calculator as part of our program, you could probably find an existing Go Package that contains the mathematical functions that you could import into your code saving you a lot of time and effort in the long run. Go encourages you to organise your code in packages so that it is easy to reuse and maintain source code.","title":"What are packages?"},{"location":"Week/01/day02-03/#hello-devopstraineeprogram-line-by-line","text":"Now let's take a look at our Hello #DevOpsTraineeProgram main.go file and walk through the lines. In the first line, you have package main which means that this file belongs to a package called main. All .go files need to belong to a package, they should also have package something in the opening line. A package can be named whatever you wish. We have to call this main as this is the starting point of the program that is going to be in this package, this is a rule. (Feel free to further research to understand more regarding this rule.) Whenever we want to compile and execute our code we have to tell the machine where the execution needs to start. We do this by writing a function called main. The machine will look for a function called main to find the entry point of the program. A function is a block of code that can do some specific task for and can be used across the program. You can declare a function with any name using func but in this case we need to name it main as this is where the code starts. Next we are going to look at line 3 of our code, the import, this basically means you want to bring in another package to your main program. fmt is a standard package being used here provided by Go, this package contains the Println() function and because we have imported this we can use this in line 6. There are a number of standard packages you can include in your program and leverage or reuse them in your code saving you the hassle of having to write from scratch. Go Standard Library the Println() that we have here is a way in which to write to a standard output to the terminal whenever the executuable has been executed succesfully. Feel free to change the message in between the () .","title":"Hello #DevOpsTraineeProgram Line by Line"},{"location":"Week/01/day02-03/#tldr","text":"Line 1 = This file will be in the package called main and this needs to be called main because includes the entry point of the program. Line 3 = For us to be able to use the Println() function, we have to import the fmt package to use this on line 6. Line 5 = The actual starting point, its the main function. Line 6 = This will let us print \"Hello #DevOpsTraineeProgram\" on our system. See you on Next Section .","title":"TLDR"},{"location":"Week/01/day02-04/","text":"The Go Workspace On the Previous Section we briefly covered the Go workspace to get Go up and running to get to the demo of Hello #DevOpsTraineeProgram But we should explain a little more about the Go workspace. Remember we chose the defaults and we then went through and created our Go folder in the GOPATH that was already defined but in reality, this GOPATH can be changed to be whatever you want it to be. If you run echo $GOPATH The output should be similar to mine (with a different username may be) which is: /home/romerocm/go Then within here, we created 3 directories. src , pkg and bin src is where all of your Go programs and projects are stored. This handles namespacing package management for all your Go repositories. This is where you will see on our workstation we have our hello folder for the Hello #DevOpsTraineeProgram project. pkg is where your archived files of packages that are or were installed in programs. This helps to speed up the compiling process based on if the packages being used have been modified. bin is where all of your compiled binaries are stored. Our Hello #DevOpsTraineeProgram is not a complex program so here is an example of a more complex Go Program taken from another great resource worth looking at GoChronicles This page also goes into some great detail about why and how the layout is like this it also goes a little deeper on other folders we have not mentioned GoChronicles Compiling & running code On a Previous Section we also covered a brief introduction to compiling code, but we can go a little deeper here. To run our code we first must compile it. There are three ways to do this within Go. go build go install go run Before we get to the above compile stage we need to take a look at what we get with the Go Installation. When we installed Go this installed something known as Go tools which consist of several programs that let us build and process our Go source files. One of the tools is Go It is worth noting that you can install additional tools that are not in the standard Go installation. If you open your command prompt and type go you should see something like the image below and then you will see \"Additional Help Topics\" below that for now we don't need to worry about those. You might also remember that we have already used at least two of these tools so far on our previous sections. The ones we want to learn more about are build, install and run. go run - This command compiles and runs the main package comprised of the .go files specified on the command line. The command is compiled to a temporary folder. go build - To compile packages and dependencies, compile the package in the current directory. If the main package, will place the executable in the current directory if not then it will place the executable in the pkg folder. go build also enables you to build an executable file for any Go Supported OS platform. go install - The same as go build but will place the executable in the bin folder We have run through go build and go run but feel free to run through them again here if you wish, go install as stated above puts the executable in our bin folder. Hopefully, if you are following along you are watching one of the playlists or videos below. The resources below are likely going to give you a much better understanding of a lot of these areas you need overall while we try to keep everything simple and straight to the point on these sections. Resources StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist See you on Day 11 .","title":"4. The Go Workspace"},{"location":"Week/01/day02-04/#the-go-workspace","text":"On the Previous Section we briefly covered the Go workspace to get Go up and running to get to the demo of Hello #DevOpsTraineeProgram But we should explain a little more about the Go workspace. Remember we chose the defaults and we then went through and created our Go folder in the GOPATH that was already defined but in reality, this GOPATH can be changed to be whatever you want it to be. If you run echo $GOPATH The output should be similar to mine (with a different username may be) which is: /home/romerocm/go Then within here, we created 3 directories. src , pkg and bin src is where all of your Go programs and projects are stored. This handles namespacing package management for all your Go repositories. This is where you will see on our workstation we have our hello folder for the Hello #DevOpsTraineeProgram project. pkg is where your archived files of packages that are or were installed in programs. This helps to speed up the compiling process based on if the packages being used have been modified. bin is where all of your compiled binaries are stored. Our Hello #DevOpsTraineeProgram is not a complex program so here is an example of a more complex Go Program taken from another great resource worth looking at GoChronicles This page also goes into some great detail about why and how the layout is like this it also goes a little deeper on other folders we have not mentioned GoChronicles","title":"The Go Workspace"},{"location":"Week/01/day02-04/#compiling-running-code","text":"On a Previous Section we also covered a brief introduction to compiling code, but we can go a little deeper here. To run our code we first must compile it. There are three ways to do this within Go. go build go install go run Before we get to the above compile stage we need to take a look at what we get with the Go Installation. When we installed Go this installed something known as Go tools which consist of several programs that let us build and process our Go source files. One of the tools is Go It is worth noting that you can install additional tools that are not in the standard Go installation. If you open your command prompt and type go you should see something like the image below and then you will see \"Additional Help Topics\" below that for now we don't need to worry about those. You might also remember that we have already used at least two of these tools so far on our previous sections. The ones we want to learn more about are build, install and run. go run - This command compiles and runs the main package comprised of the .go files specified on the command line. The command is compiled to a temporary folder. go build - To compile packages and dependencies, compile the package in the current directory. If the main package, will place the executable in the current directory if not then it will place the executable in the pkg folder. go build also enables you to build an executable file for any Go Supported OS platform. go install - The same as go build but will place the executable in the bin folder We have run through go build and go run but feel free to run through them again here if you wish, go install as stated above puts the executable in our bin folder. Hopefully, if you are following along you are watching one of the playlists or videos below. The resources below are likely going to give you a much better understanding of a lot of these areas you need overall while we try to keep everything simple and straight to the point on these sections.","title":"Compiling &amp; running code"},{"location":"Week/01/day02-04/#resources","text":"StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist See you on Day 11 .","title":"Resources"},{"location":"Week/01/day02-05/","text":"Before we get into the topics for today I want to give a massive shout out to Techworld with Nana and this fantastic concise journey through the fundamentals of Go. On Section 2 we set our environment up, on Section 3 we walked through the Hello #DevOpsTraineeProgram code and on Section 4 ) we looked at our Go workspace and went a little deeper into compiling and running the code. We are now going to take a look into Variables, Constants and Data Types whilst writing a new program. Variables & Constants in Go Let's start by planning our application, I think it would be a good idea to work on a program that tells us how many days we have remain in our #DevOpsTraineeProgram. The first thing to consider here is that as we are building our app and we are welcoming our attendees and we are giving the user feedback on the number of days they have completed we might use the term #DevOpsTraineeProgram many times throughout the program. This is a great use case to make #DevOpsTraineeProgram a variable within our program. Variables are used to store values. Like a little box with our saved information or values. We can then use this variable across the program which also benefits that if this challenge or variable changes then we only have to change this in one place. Meaning we could translate this to other challenges we have in the community by just changing that one variable value. To declare this in our Go Program we define a value by using a keyword for variables. This will live within our func main block of code that you will see later. You can find more about Keywords here. Remember to make sure that your variable names are descriptive. If you declare a variable you must use it or you will get an error, this is to avoid possible dead code, code that is never used. This is the same for packages not used. var challenge = \"#DevOpsTraineeProgram\" With the above set and used as we will see in the next code snippet you can see from the output below that we have used a variable. package main import \"fmt\" func main() { var challenge = \"#DevOpsTraineeProgram\" fmt.Println(\"Welcome to\", challenge, \"\") } You can find the above code snippet on Pastebin You will then see from the below that we built our code with the above example and we got the output shown below. We also know that our challenge is 60 days at least but maybe we'd like to extend it to 90 in the future! If this is the case, we'd want to define a variable to help us be as flexible as possible. However, for our this program and exercise we want to define it as a constant. Constants are like variables, except that their value cannot be changed within code (we can still create a new app later down the line with this same snippet of code and decide to change this constant but this 60 value will not change whilst we are running our application) Adding the const to our code and adding another line of code to print this. package main import \"fmt\" func main() { var challenge = \"#DevOpsTraineeProgram\" const daystotal = 60 fmt.Println(\"Welcome to\", challenge) fmt.Println(\"This is a\", daystotal, \"challenge\") } You can find the above code snippet on Pastebin If we then go through that go build process again and run you will see below the outcome. Finally, and this won't be the end of our program we will come back to this in next Sections to add more functionality. We now want to add another variable for the number of days we have completed the challenge. Below we've added dayscomplete variable with the number of days completed. package main import \"fmt\" func main() { var challenge = \"#DevOpsTraineeProgram\" const daystotal = 60 var dayscomplete = 11 fmt.Println(\"Welcome to\", challenge, \"\") fmt.Println(\"This is a\", daystotal, \"challenge and you have completed\", dayscomplete, \"days\") fmt.Println(\"Great work\") } You can find the above code snippet on Pastebin Let's run through that go build process again or you could just use go run Here are some other examples that I have used to make the code easier to read and edit. We have up till now been using Println but we can simplify this by using Printf by using %v which means we define our variables in order at the end of the line of code. we also use \\n for a line break. I am using %v as this uses a default value but there are other options that can be found here in the fmt package documentation you can find the code example here : package main import \"fmt\" func main() { var challenge = \"#DevOpsTraineeProgram\" const daystotal = 90 var dayscomplete = 11 fmt.Printf(\"Welcome to %v\\n\", challenge) fmt.Printf(\"This is a %v challenge and you have completed %v days\\n\", daystotal, dayscomplete) fmt.Println(\"Great work\") } Variables may also be defined in a simpler format in your code. Instead of defining that it is a var and the type you can code this as follows to get the same functionality but a nice cleaner and simpler look for your code. This will only work for variables though and not constants. func main() { challenge := \"#DevOpsTraineeProgram\" const daystotal = 60 Data Types In the above examples, we have not defined the type of variables, this is because we can give it a value here and Go is smart enough to know what that type is or at least can infer what it is based on the value you have stored. However, if we want a user to input this will require a specific type. We have used Strings and Integers in our code so far. Integers for the number of days and strings are for the name of the challenge. It is also important to note that each data type can do different things and behaves differently. For example, integers can multiply where strings do not. There are four categories Basic type : Numbers, strings, and booleans come under this category. Aggregate type : Array and structs come under this category. Reference type : Pointers, slices, maps, functions, and channels come under this category. Interface type The data type is an important concept in programming. Data type specifies the size and type of variable values. Go is statically typed, meaning that once a variable type is defined, it can only store data of that type. Go has three basic data types: bool : represents a boolean value and is either true or false Numeric : represents integer types, floating-point values, and complex types string : represents a string value I found this resource super detailed on data types Golang by example I would also suggest Techworld with Nana at this point covers in some detail a lot about the data types in Go. If we need to define a type in our variable we can do this like so: var TwitterHandle string var DaysCompleted uint Because Go implies variables where a value is given we can print out those values with the following: fmt.Printf(\"challenge is %T, daystotal is %T, dayscomplete is %T\\n\", conference, daystotal, dayscomplete) There are many different types of integer and float types the links above will cover off these in detail. int = whole numbers unint = positive whole numbers floating point types = numbers that contain a decimal component Next up we are going to start adding some user input functionality to our program so that we are asking how many days have been completed. See you on Next Section .","title":"5. Variables & Constants in Go"},{"location":"Week/01/day02-05/#variables-constants-in-go","text":"Let's start by planning our application, I think it would be a good idea to work on a program that tells us how many days we have remain in our #DevOpsTraineeProgram. The first thing to consider here is that as we are building our app and we are welcoming our attendees and we are giving the user feedback on the number of days they have completed we might use the term #DevOpsTraineeProgram many times throughout the program. This is a great use case to make #DevOpsTraineeProgram a variable within our program. Variables are used to store values. Like a little box with our saved information or values. We can then use this variable across the program which also benefits that if this challenge or variable changes then we only have to change this in one place. Meaning we could translate this to other challenges we have in the community by just changing that one variable value. To declare this in our Go Program we define a value by using a keyword for variables. This will live within our func main block of code that you will see later. You can find more about Keywords here. Remember to make sure that your variable names are descriptive. If you declare a variable you must use it or you will get an error, this is to avoid possible dead code, code that is never used. This is the same for packages not used. var challenge = \"#DevOpsTraineeProgram\" With the above set and used as we will see in the next code snippet you can see from the output below that we have used a variable. package main import \"fmt\" func main() { var challenge = \"#DevOpsTraineeProgram\" fmt.Println(\"Welcome to\", challenge, \"\") } You can find the above code snippet on Pastebin You will then see from the below that we built our code with the above example and we got the output shown below. We also know that our challenge is 60 days at least but maybe we'd like to extend it to 90 in the future! If this is the case, we'd want to define a variable to help us be as flexible as possible. However, for our this program and exercise we want to define it as a constant. Constants are like variables, except that their value cannot be changed within code (we can still create a new app later down the line with this same snippet of code and decide to change this constant but this 60 value will not change whilst we are running our application) Adding the const to our code and adding another line of code to print this. package main import \"fmt\" func main() { var challenge = \"#DevOpsTraineeProgram\" const daystotal = 60 fmt.Println(\"Welcome to\", challenge) fmt.Println(\"This is a\", daystotal, \"challenge\") } You can find the above code snippet on Pastebin If we then go through that go build process again and run you will see below the outcome. Finally, and this won't be the end of our program we will come back to this in next Sections to add more functionality. We now want to add another variable for the number of days we have completed the challenge. Below we've added dayscomplete variable with the number of days completed. package main import \"fmt\" func main() { var challenge = \"#DevOpsTraineeProgram\" const daystotal = 60 var dayscomplete = 11 fmt.Println(\"Welcome to\", challenge, \"\") fmt.Println(\"This is a\", daystotal, \"challenge and you have completed\", dayscomplete, \"days\") fmt.Println(\"Great work\") } You can find the above code snippet on Pastebin Let's run through that go build process again or you could just use go run Here are some other examples that I have used to make the code easier to read and edit. We have up till now been using Println but we can simplify this by using Printf by using %v which means we define our variables in order at the end of the line of code. we also use \\n for a line break. I am using %v as this uses a default value but there are other options that can be found here in the fmt package documentation you can find the code example here : package main import \"fmt\" func main() { var challenge = \"#DevOpsTraineeProgram\" const daystotal = 90 var dayscomplete = 11 fmt.Printf(\"Welcome to %v\\n\", challenge) fmt.Printf(\"This is a %v challenge and you have completed %v days\\n\", daystotal, dayscomplete) fmt.Println(\"Great work\") } Variables may also be defined in a simpler format in your code. Instead of defining that it is a var and the type you can code this as follows to get the same functionality but a nice cleaner and simpler look for your code. This will only work for variables though and not constants. func main() { challenge := \"#DevOpsTraineeProgram\" const daystotal = 60","title":"Variables &amp; Constants in Go"},{"location":"Week/01/day02-05/#data-types","text":"In the above examples, we have not defined the type of variables, this is because we can give it a value here and Go is smart enough to know what that type is or at least can infer what it is based on the value you have stored. However, if we want a user to input this will require a specific type. We have used Strings and Integers in our code so far. Integers for the number of days and strings are for the name of the challenge. It is also important to note that each data type can do different things and behaves differently. For example, integers can multiply where strings do not. There are four categories Basic type : Numbers, strings, and booleans come under this category. Aggregate type : Array and structs come under this category. Reference type : Pointers, slices, maps, functions, and channels come under this category. Interface type The data type is an important concept in programming. Data type specifies the size and type of variable values. Go is statically typed, meaning that once a variable type is defined, it can only store data of that type. Go has three basic data types: bool : represents a boolean value and is either true or false Numeric : represents integer types, floating-point values, and complex types string : represents a string value I found this resource super detailed on data types Golang by example I would also suggest Techworld with Nana at this point covers in some detail a lot about the data types in Go. If we need to define a type in our variable we can do this like so: var TwitterHandle string var DaysCompleted uint Because Go implies variables where a value is given we can print out those values with the following: fmt.Printf(\"challenge is %T, daystotal is %T, dayscomplete is %T\\n\", conference, daystotal, dayscomplete) There are many different types of integer and float types the links above will cover off these in detail. int = whole numbers unint = positive whole numbers floating point types = numbers that contain a decimal component Next up we are going to start adding some user input functionality to our program so that we are asking how many days have been completed. See you on Next Section .","title":"Data Types"},{"location":"Week/01/day02-06/","text":"Getting user input with Pointers and a finished program On the ( Previous Section ), we created our first Go program that was self-contained and the parts we wanted to get user input for were created as variables within our code and given values, we now want to ask the user for their input to give the variable the value for the end message. Getting user input Before we do that let's take a look at our application again and walk through the variables we want as a test before getting that user input. Yesterday we finished up with our code looking like this: we have manually in code defined our challenge, daystotal, dayscomplete variables and constants. Let's now add a new variable called TwitterName you can find this new code in Pastebin and if we run this code this is our output: If we were on Week 01 and we would need to change that dayscomplete every day and compile our code each day if this was hardcoded which doesn't sound so great. Getting user input, we want to get the value of maybe a name and the number of days completed. For us to do this we can use another function from within the fmt package. Recap on the fmt package, different functions for: formatted input and output (I/O) Print Messages Collect User Input Write into a file This is instead of assigning the value of a variable we want to ask the user for their input. fmt.Scan(&TwitterName) Notice that we also use & before the variable. This is known as a pointer which we will cover in the next section. In our code: package main import \"fmt\" func main() { const DaysTotal int = 60 challenge := \"#DevOpsTraineeProgram\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(&TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(&DaysCompleted) fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) fmt.Println(\"Good luck\") } You can see that we are asking the user to input two variables, TwitterName and DaysCompleted Let's now run our program and you see we have input for both of the above. Ok, that's great we got some user input and we printed a message but what about getting our program to tell us how many days we have left in our challenge. For us to do that we have created a variable called remainingDays and we have hard valued this in our code as 90 we then need to change the value of this value to print out the remaining days when we get our user input of DaysCompleted we can do this with this simple variable change. remainingDays = remainingDays - DaysCompleted You can see how our finished program looks here: package main import \"fmt\" func main() { const DaysTotal int = 60 var remainingDays uint = 60 challenge := \"#DevOpsTraineeProgram\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(&TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(&DaysCompleted) // calculate remaining days remainingDays = remainingDays - DaysCompleted fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) fmt.Printf(\"You have %v days remaining for the %v challenge\\n\", remainingDays, challenge) fmt.Println(\"Good luck\") } If we now run this program you can see that simple calculation is made based on the user input and the value of the remainingDays What is a pointer? (Special Variables) A pointer is a (special) variable that points to the memory address of another variable. A great explanation of this can be found here at geeksforgeeks Let's simplify our code now and show with and without the & in front of one of our print commands, this gives us the memory address of the pointer. I have added this code example here: package main import \"fmt\" func main() { var challenge = \"#DevOpsTraineeProgram\" fmt.Println(challenge) fmt.Println(&challenge) } Below is running this code. Resources StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist See you on Next Section .","title":"6. Getting user input with Pointers and a finished program"},{"location":"Week/01/day02-06/#getting-user-input-with-pointers-and-a-finished-program","text":"On the ( Previous Section ), we created our first Go program that was self-contained and the parts we wanted to get user input for were created as variables within our code and given values, we now want to ask the user for their input to give the variable the value for the end message.","title":"Getting user input with Pointers and a finished program"},{"location":"Week/01/day02-06/#getting-user-input","text":"Before we do that let's take a look at our application again and walk through the variables we want as a test before getting that user input. Yesterday we finished up with our code looking like this: we have manually in code defined our challenge, daystotal, dayscomplete variables and constants. Let's now add a new variable called TwitterName you can find this new code in Pastebin and if we run this code this is our output: If we were on Week 01 and we would need to change that dayscomplete every day and compile our code each day if this was hardcoded which doesn't sound so great. Getting user input, we want to get the value of maybe a name and the number of days completed. For us to do this we can use another function from within the fmt package. Recap on the fmt package, different functions for: formatted input and output (I/O) Print Messages Collect User Input Write into a file This is instead of assigning the value of a variable we want to ask the user for their input. fmt.Scan(&TwitterName) Notice that we also use & before the variable. This is known as a pointer which we will cover in the next section. In our code: package main import \"fmt\" func main() { const DaysTotal int = 60 challenge := \"#DevOpsTraineeProgram\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(&TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(&DaysCompleted) fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) fmt.Println(\"Good luck\") } You can see that we are asking the user to input two variables, TwitterName and DaysCompleted Let's now run our program and you see we have input for both of the above. Ok, that's great we got some user input and we printed a message but what about getting our program to tell us how many days we have left in our challenge. For us to do that we have created a variable called remainingDays and we have hard valued this in our code as 90 we then need to change the value of this value to print out the remaining days when we get our user input of DaysCompleted we can do this with this simple variable change. remainingDays = remainingDays - DaysCompleted You can see how our finished program looks here: package main import \"fmt\" func main() { const DaysTotal int = 60 var remainingDays uint = 60 challenge := \"#DevOpsTraineeProgram\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(&TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(&DaysCompleted) // calculate remaining days remainingDays = remainingDays - DaysCompleted fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) fmt.Printf(\"You have %v days remaining for the %v challenge\\n\", remainingDays, challenge) fmt.Println(\"Good luck\") } If we now run this program you can see that simple calculation is made based on the user input and the value of the remainingDays","title":"Getting user input"},{"location":"Week/01/day02-06/#what-is-a-pointer-special-variables","text":"A pointer is a (special) variable that points to the memory address of another variable. A great explanation of this can be found here at geeksforgeeks Let's simplify our code now and show with and without the & in front of one of our print commands, this gives us the memory address of the pointer. I have added this code example here: package main import \"fmt\" func main() { var challenge = \"#DevOpsTraineeProgram\" fmt.Println(challenge) fmt.Println(&challenge) } Below is running this code.","title":"What is a pointer? (Special Variables)"},{"location":"Week/01/day02-06/#resources","text":"StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist See you on Next Section .","title":"Resources"},{"location":"Week/01/day02-07/","text":"Tweet your progress with our new App As we are nearing to our last section, we must highlight that we have only just touched the surface here and it is just the start that might get you hooked or interested and excited. Maybe it is your beginning to wanting to dive more into Go. So far, we have taken a small idea for an application and we have added functionality to it. In this session we want to take advantage of those packages we mentioned earlier and create the functionality for our app to not only give you the update of your progress on screen but also send a tweet with the details of the challenge and your status. Adding the ability to tweet your progress The first thing we need to do is set up our developer API access with Twitter for this to work. Head to the Twitter Developer Platform and sign in with your Twitter handle and details and make sure to sign up for your access for twitter developer dashboard. Once in you should see something like the screenshot below. Make sure to use the name dpt-yourname as your app name to ensure it is unique. From here you may also want to request elevated access, this might take some time but generally it shouldn't take too long. Next, we should select Projects & Apps and create our App. Limits are depending on the account access you have, with essential you only have one app and one project which is enough however with elevated you can have a total of 3 apps. For now, one app is enough for this case scenario. Note: You will be then given API tokens, it is important that you save these somewhere secure. (I have since deleted this app) We will need these later with our Go Application. Now that we have our app created, make sure that they're unique to you. The keys that we gathered before are known as our consumer keys and we will also need our access token and secrets. We can gather this information using the \"Keys & Tokens\" tab. Okay, we are done in the Twitter developer portal for now. Make sure you keep your keys safe because we will need them later. Go Twitter Bot Remember the code we are starting within our application as well: package main import \"fmt\" func main() { const DaysTotal int = 60 var remainingDays uint = 60 challenge := \"#DevOpsTraineeProgram\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(&TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(&DaysCompleted) // calculate remaining days remainingDays = remainingDays - DaysCompleted fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) fmt.Printf(\"You have %v days remaining for the %v challenge\\n\", remainingDays, challenge) fmt.Println(\"Good luck\") } but first, we need to check we have the correct code to make something tweet. We need to think about the code to get our output or message to Twitter in the form of a tweet. We are going to be using go-twitter This is a Go client library for the Twitter API. To test this before putting this into our main application, we have created a new directory in our src folder called go-twitter-bot, issued the go mod init github.com/michaelcade/go-twitter-bot on the folder which then created a go.mod file and then we can start writing our new main.go and test this out. Additionally we will need to add the following packages: go get package github.com/dghubble/go-twitter/twitter go get package github.com/dghubble/oauth1 We now need those keys, tokens and secrets we gathered from the Twitter developer portal. We are going to set these in our environment variables. This will depend on the OS you are running: Windows set CONSUMER_KEY set CONSUMER_SECRET set ACCESS_TOKEN set ACCESS_TOKEN_SECRET Linux / macOS export CONSUMER_KEY export CONSUMER_SECRET export ACCESS_TOKEN export ACCESS_TOKEN_SECRET At this stage, you can take a look at the following code but you will see here that we are using a struct to define our keys, secrets and tokens. We then have a func to parse those credentials and make that connection to the Twitter API Then based on the success we will then send a tweet. package main import ( // other imports \"fmt\" \"log\" \"os\" \"github.com/dghubble/go-twitter/twitter\" \"github.com/dghubble/oauth1\" ) // Credentials stores all of our access/consumer tokens // and secret keys needed for authentication against // the twitter REST API. type Credentials struct { ConsumerKey string ConsumerSecret string AccessToken string AccessTokenSecret string } // getClient is a helper function that will return a twitter client // that we can subsequently use to send tweets, or to stream new tweets // this will take in a pointer to a Credential struct which will contain // everything needed to authenticate and return a pointer to a twitter Client // or an error func getClient(creds *Credentials) (*twitter.Client, error) { // Pass in your consumer key (API Key) and your Consumer Secret (API Secret) config := oauth1.NewConfig(creds.ConsumerKey, creds.ConsumerSecret) // Pass in your Access Token and your Access Token Secret token := oauth1.NewToken(creds.AccessToken, creds.AccessTokenSecret) httpClient := config.Client(oauth1.NoContext, token) client := twitter.NewClient(httpClient) // Verify Credentials verifyParams := &twitter.AccountVerifyParams{ SkipStatus: twitter.Bool(true), IncludeEmail: twitter.Bool(true), } // we can retrieve the user and verify if the credentials // we have used successfully allow us to log in! user, _, err := client.Accounts.VerifyCredentials(verifyParams) if err != nil { return nil, err } log.Printf(\"User's ACCOUNT:\\n%+v\\n\", user) return client, nil } func main() { fmt.Println(\"Go-Twitter Bot v0.01\") creds := Credentials{ AccessToken: os.Getenv(\"ACCESS_TOKEN\"), AccessTokenSecret: os.Getenv(\"ACCESS_TOKEN_SECRET\"), ConsumerKey: os.Getenv(\"CONSUMER_KEY\"),` ConsumerSecret: os.Getenv(\"CONSUMER_SECRET\"), } client, err := getClient(&creds) if err != nil { log.Println(\"Error getting Twitter Client\") log.Println(err) } tweet, resp, err := client.Statuses.Update(\"A Test Tweet from the future, testing a #DevOpsTraineeProgram Program that tweets, tweet tweet\", nil) if err != nil { log.Println(err) } log.Printf(\"%+v\\n\", resp) log.Printf(\"%+v\\n\", tweet) } The above will either give you an error based on what is happening or it will succeed and you will have a tweet sent with the message outlined in the code. Pairing the two together - Go-Twitter-Bot + Our App Now we need to merge these two in our main.go . We can definitely improve this in the future as we build our .go files in our project but for now this will make sense. You can see the merged codebase here but I will also show it below. package main import ( // other imports \"fmt\" \"log\" \"os\" \"github.com/dghubble/go-twitter/twitter\" \"github.com/dghubble/oauth1\" ) // Credentials stores all of our access/consumer tokens // and secret keys needed for authentication against // the twitter REST API. type Credentials struct { ConsumerKey string ConsumerSecret string AccessToken string AccessTokenSecret string } // getClient is a helper function that will return a twitter client // that we can subsequently use to send tweets, or to stream new tweets // this will take in a pointer to a Credential struct which will contain // everything needed to authenticate and return a pointer to a twitter Client // or an error func getClient(creds *Credentials) (*twitter.Client, error) { // Pass in your consumer key (API Key) and your Consumer Secret (API Secret) config := oauth1.NewConfig(creds.ConsumerKey, creds.ConsumerSecret) // Pass in your Access Token and your Access Token Secret token := oauth1.NewToken(creds.AccessToken, creds.AccessTokenSecret) httpClient := config.Client(oauth1.NoContext, token) client := twitter.NewClient(httpClient) // Verify Credentials verifyParams := &twitter.AccountVerifyParams{ SkipStatus: twitter.Bool(true), IncludeEmail: twitter.Bool(true), } // we can retrieve the user and verify if the credentials // we have used successfully allow us to log in! user, _, err := client.Accounts.VerifyCredentials(verifyParams) if err != nil { return nil, err } log.Printf(\"User's ACCOUNT:\\n%+v\\n\", user) return client, nil } func main() { creds := Credentials{ AccessToken: os.Getenv(\"ACCESS_TOKEN\"), AccessTokenSecret: os.Getenv(\"ACCESS_TOKEN_SECRET\"), ConsumerKey: os.Getenv(\"CONSUMER_KEY\"), ConsumerSecret: os.Getenv(\"CONSUMER_SECRET\"), } { const DaysTotal int = 60 var remainingDays uint = 60 challenge := \"#DevOpsTraineeProgram\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(&TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(&DaysCompleted) // calculate remaining days remainingDays = remainingDays - DaysCompleted //fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) //fmt.Printf(\"You have %v days remaining for the %v challenge\\n\", remainingDays, challenge) // fmt.Println(\"Good luck\") client, err := getClient(&creds) if err != nil { log.Println(\"Error getting Twitter Client, this is expected if you did not supply your Twitter API tokens\") log.Println(err) } message := fmt.Sprintf(\"Hey I am %v I have been doing the %v for %v days and I have %v Days left\", TwitterName, challenge, DaysCompleted, remainingDays) tweet, resp, err := client.Statuses.Update(message, nil) if err != nil { log.Println(err) } log.Printf(\"%+v\\n\", resp) log.Printf(\"%+v\\n\", tweet) } } Note The outcome of this should be a tweet but if you did not supply your environment variables then you should get an error like the one below. You also need to apply for elevated access, otherwise you'll get the following error message when you are trying to send your tweet: Once you have fixed that, the resulting tweet should look something like this: How to compile for multiple OSs I next want to cover the question, \"How do you compile for multiple Operating Systems?\" The great thing about Go is that it can easily compile for many different Operating Systems. You can get a full list by running the following command: go tool dist list Using our go build commands so far is great and it will use the GOOS and GOARCH environment variables to determine the host machine and what the build should be built for. But we can also create other binaries by using the code below as an example. GOARCH=amd64 GOOS=darwin go build -o ${BINARY_NAME}_0.1_darwin main.go GOARCH=amd64 GOOS=linux go build -o ${BINARY_NAME}_0.1_linux main.go GOARCH=amd64 GOOS=windows go build -o ${BINARY_NAME}_0.1_windows main.go GOARCH=arm64 GOOS=linux go build -o ${BINARY_NAME}_0.1_linux_arm64 main.go GOARCH=arm64 GOOS=darwin go build -o ${BINARY_NAME}_0.1_darwin_arm64 main.go This will then give you binaries in your directory for all of the above platforms. You can then take this and create a makefile to build these binaries whenever you add new features and functionality to your code. I have included the makefile This is what I have used to create the releases you can now see on the repository Resources StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist A great repo full of all things DevOps & exercises GoByExample - Example based learning go.dev/tour/list go.dev/learn This wraps up the Programming language for now! So much more that can be covered and I hope you have been able to continue through the content above and be able to understand some of the other aspects of the Go programming language. Next, we take our focus into Linux and some of the fundamentals that we should all know here. See you in the Next Section .","title":"7. Tweet your progress with our new App"},{"location":"Week/01/day02-07/#tweet-your-progress-with-our-new-app","text":"As we are nearing to our last section, we must highlight that we have only just touched the surface here and it is just the start that might get you hooked or interested and excited. Maybe it is your beginning to wanting to dive more into Go. So far, we have taken a small idea for an application and we have added functionality to it. In this session we want to take advantage of those packages we mentioned earlier and create the functionality for our app to not only give you the update of your progress on screen but also send a tweet with the details of the challenge and your status.","title":"Tweet your progress with our new App"},{"location":"Week/01/day02-07/#adding-the-ability-to-tweet-your-progress","text":"The first thing we need to do is set up our developer API access with Twitter for this to work. Head to the Twitter Developer Platform and sign in with your Twitter handle and details and make sure to sign up for your access for twitter developer dashboard. Once in you should see something like the screenshot below. Make sure to use the name dpt-yourname as your app name to ensure it is unique. From here you may also want to request elevated access, this might take some time but generally it shouldn't take too long. Next, we should select Projects & Apps and create our App. Limits are depending on the account access you have, with essential you only have one app and one project which is enough however with elevated you can have a total of 3 apps. For now, one app is enough for this case scenario.","title":"Adding the ability to tweet your progress"},{"location":"Week/01/day02-07/#note","text":"You will be then given API tokens, it is important that you save these somewhere secure. (I have since deleted this app) We will need these later with our Go Application. Now that we have our app created, make sure that they're unique to you. The keys that we gathered before are known as our consumer keys and we will also need our access token and secrets. We can gather this information using the \"Keys & Tokens\" tab. Okay, we are done in the Twitter developer portal for now. Make sure you keep your keys safe because we will need them later.","title":"Note:"},{"location":"Week/01/day02-07/#go-twitter-bot","text":"Remember the code we are starting within our application as well: package main import \"fmt\" func main() { const DaysTotal int = 60 var remainingDays uint = 60 challenge := \"#DevOpsTraineeProgram\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(&TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(&DaysCompleted) // calculate remaining days remainingDays = remainingDays - DaysCompleted fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) fmt.Printf(\"You have %v days remaining for the %v challenge\\n\", remainingDays, challenge) fmt.Println(\"Good luck\") } but first, we need to check we have the correct code to make something tweet. We need to think about the code to get our output or message to Twitter in the form of a tweet. We are going to be using go-twitter This is a Go client library for the Twitter API. To test this before putting this into our main application, we have created a new directory in our src folder called go-twitter-bot, issued the go mod init github.com/michaelcade/go-twitter-bot on the folder which then created a go.mod file and then we can start writing our new main.go and test this out. Additionally we will need to add the following packages: go get package github.com/dghubble/go-twitter/twitter go get package github.com/dghubble/oauth1 We now need those keys, tokens and secrets we gathered from the Twitter developer portal. We are going to set these in our environment variables. This will depend on the OS you are running: Windows set CONSUMER_KEY set CONSUMER_SECRET set ACCESS_TOKEN set ACCESS_TOKEN_SECRET Linux / macOS export CONSUMER_KEY export CONSUMER_SECRET export ACCESS_TOKEN export ACCESS_TOKEN_SECRET At this stage, you can take a look at the following code but you will see here that we are using a struct to define our keys, secrets and tokens. We then have a func to parse those credentials and make that connection to the Twitter API Then based on the success we will then send a tweet. package main import ( // other imports \"fmt\" \"log\" \"os\" \"github.com/dghubble/go-twitter/twitter\" \"github.com/dghubble/oauth1\" ) // Credentials stores all of our access/consumer tokens // and secret keys needed for authentication against // the twitter REST API. type Credentials struct { ConsumerKey string ConsumerSecret string AccessToken string AccessTokenSecret string } // getClient is a helper function that will return a twitter client // that we can subsequently use to send tweets, or to stream new tweets // this will take in a pointer to a Credential struct which will contain // everything needed to authenticate and return a pointer to a twitter Client // or an error func getClient(creds *Credentials) (*twitter.Client, error) { // Pass in your consumer key (API Key) and your Consumer Secret (API Secret) config := oauth1.NewConfig(creds.ConsumerKey, creds.ConsumerSecret) // Pass in your Access Token and your Access Token Secret token := oauth1.NewToken(creds.AccessToken, creds.AccessTokenSecret) httpClient := config.Client(oauth1.NoContext, token) client := twitter.NewClient(httpClient) // Verify Credentials verifyParams := &twitter.AccountVerifyParams{ SkipStatus: twitter.Bool(true), IncludeEmail: twitter.Bool(true), } // we can retrieve the user and verify if the credentials // we have used successfully allow us to log in! user, _, err := client.Accounts.VerifyCredentials(verifyParams) if err != nil { return nil, err } log.Printf(\"User's ACCOUNT:\\n%+v\\n\", user) return client, nil } func main() { fmt.Println(\"Go-Twitter Bot v0.01\") creds := Credentials{ AccessToken: os.Getenv(\"ACCESS_TOKEN\"), AccessTokenSecret: os.Getenv(\"ACCESS_TOKEN_SECRET\"), ConsumerKey: os.Getenv(\"CONSUMER_KEY\"),` ConsumerSecret: os.Getenv(\"CONSUMER_SECRET\"), } client, err := getClient(&creds) if err != nil { log.Println(\"Error getting Twitter Client\") log.Println(err) } tweet, resp, err := client.Statuses.Update(\"A Test Tweet from the future, testing a #DevOpsTraineeProgram Program that tweets, tweet tweet\", nil) if err != nil { log.Println(err) } log.Printf(\"%+v\\n\", resp) log.Printf(\"%+v\\n\", tweet) } The above will either give you an error based on what is happening or it will succeed and you will have a tweet sent with the message outlined in the code.","title":"Go Twitter Bot"},{"location":"Week/01/day02-07/#pairing-the-two-together-go-twitter-bot-our-app","text":"Now we need to merge these two in our main.go . We can definitely improve this in the future as we build our .go files in our project but for now this will make sense. You can see the merged codebase here but I will also show it below. package main import ( // other imports \"fmt\" \"log\" \"os\" \"github.com/dghubble/go-twitter/twitter\" \"github.com/dghubble/oauth1\" ) // Credentials stores all of our access/consumer tokens // and secret keys needed for authentication against // the twitter REST API. type Credentials struct { ConsumerKey string ConsumerSecret string AccessToken string AccessTokenSecret string } // getClient is a helper function that will return a twitter client // that we can subsequently use to send tweets, or to stream new tweets // this will take in a pointer to a Credential struct which will contain // everything needed to authenticate and return a pointer to a twitter Client // or an error func getClient(creds *Credentials) (*twitter.Client, error) { // Pass in your consumer key (API Key) and your Consumer Secret (API Secret) config := oauth1.NewConfig(creds.ConsumerKey, creds.ConsumerSecret) // Pass in your Access Token and your Access Token Secret token := oauth1.NewToken(creds.AccessToken, creds.AccessTokenSecret) httpClient := config.Client(oauth1.NoContext, token) client := twitter.NewClient(httpClient) // Verify Credentials verifyParams := &twitter.AccountVerifyParams{ SkipStatus: twitter.Bool(true), IncludeEmail: twitter.Bool(true), } // we can retrieve the user and verify if the credentials // we have used successfully allow us to log in! user, _, err := client.Accounts.VerifyCredentials(verifyParams) if err != nil { return nil, err } log.Printf(\"User's ACCOUNT:\\n%+v\\n\", user) return client, nil } func main() { creds := Credentials{ AccessToken: os.Getenv(\"ACCESS_TOKEN\"), AccessTokenSecret: os.Getenv(\"ACCESS_TOKEN_SECRET\"), ConsumerKey: os.Getenv(\"CONSUMER_KEY\"), ConsumerSecret: os.Getenv(\"CONSUMER_SECRET\"), } { const DaysTotal int = 60 var remainingDays uint = 60 challenge := \"#DevOpsTraineeProgram\" fmt.Printf(\"Welcome to the %v challenge.\\nThis challenge consists of %v days\\n\", challenge, DaysTotal) var TwitterName string var DaysCompleted uint // asking for user input fmt.Println(\"Enter Your Twitter Handle: \") fmt.Scanln(&TwitterName) fmt.Println(\"How many days have you completed?: \") fmt.Scanln(&DaysCompleted) // calculate remaining days remainingDays = remainingDays - DaysCompleted //fmt.Printf(\"Thank you %v for taking part and completing %v days.\\n\", TwitterName, DaysCompleted) //fmt.Printf(\"You have %v days remaining for the %v challenge\\n\", remainingDays, challenge) // fmt.Println(\"Good luck\") client, err := getClient(&creds) if err != nil { log.Println(\"Error getting Twitter Client, this is expected if you did not supply your Twitter API tokens\") log.Println(err) } message := fmt.Sprintf(\"Hey I am %v I have been doing the %v for %v days and I have %v Days left\", TwitterName, challenge, DaysCompleted, remainingDays) tweet, resp, err := client.Statuses.Update(message, nil) if err != nil { log.Println(err) } log.Printf(\"%+v\\n\", resp) log.Printf(\"%+v\\n\", tweet) } }","title":"Pairing the two together - Go-Twitter-Bot + Our App"},{"location":"Week/01/day02-07/#note_1","text":"The outcome of this should be a tweet but if you did not supply your environment variables then you should get an error like the one below. You also need to apply for elevated access, otherwise you'll get the following error message when you are trying to send your tweet: Once you have fixed that, the resulting tweet should look something like this:","title":"Note"},{"location":"Week/01/day02-07/#how-to-compile-for-multiple-oss","text":"I next want to cover the question, \"How do you compile for multiple Operating Systems?\" The great thing about Go is that it can easily compile for many different Operating Systems. You can get a full list by running the following command: go tool dist list Using our go build commands so far is great and it will use the GOOS and GOARCH environment variables to determine the host machine and what the build should be built for. But we can also create other binaries by using the code below as an example. GOARCH=amd64 GOOS=darwin go build -o ${BINARY_NAME}_0.1_darwin main.go GOARCH=amd64 GOOS=linux go build -o ${BINARY_NAME}_0.1_linux main.go GOARCH=amd64 GOOS=windows go build -o ${BINARY_NAME}_0.1_windows main.go GOARCH=arm64 GOOS=linux go build -o ${BINARY_NAME}_0.1_linux_arm64 main.go GOARCH=arm64 GOOS=darwin go build -o ${BINARY_NAME}_0.1_darwin_arm64 main.go This will then give you binaries in your directory for all of the above platforms. You can then take this and create a makefile to build these binaries whenever you add new features and functionality to your code. I have included the makefile This is what I have used to create the releases you can now see on the repository","title":"How to compile for multiple OSs"},{"location":"Week/01/day02-07/#resources","text":"StackOverflow 2021 Developer Survey Why we are choosing Golang to learn Jake Wright - Learn Go in 12 minutes Techworld with Nana - Golang full course - 3 hours 24 mins NOT FREE Nigel Poulton Pluralsight - Go Fundamentals - 3 hours 26 mins FreeCodeCamp - Learn Go Programming - Golang Tutorial for Beginners Hitesh Choudhary - Complete playlist A great repo full of all things DevOps & exercises GoByExample - Example based learning go.dev/tour/list go.dev/learn This wraps up the Programming language for now! So much more that can be covered and I hope you have been able to continue through the content above and be able to understand some of the other aspects of the Go programming language. Next, we take our focus into Linux and some of the fundamentals that we should all know here. See you in the Next Section .","title":"Resources"},{"location":"Week/01/day03-01/","text":"The Big Picture: DevOps and Linux Linux and DevOps share very similar cultures and perspectives; both are focused on customization and scalability. Both of these aspects of Linux are of particular importance for DevOps. A lot of technologies start on Linux, especially if they are related to software development or managing infrastructure. As well lots of open source projects, especially DevOps tools, were designed to run on Linux from the start. From a DevOps perspective or in fact any operations role perspective you are going to come across Linux I would say mostly. There is a place for WinOps but the majority of the time you are going to be administering and deploying Linux servers. I have been using Linux on a daily basis for a number of years but my go to desktop machine has always been either macOS or Windows. However, when I moved into the Cloud Native role I am in now I took the plunge to make sure that my laptop was fully Linux based and my daily driver, whilst I still needed Windows for some work-based applications at times and a lot of my audio and video gear does not run on Linux I was forcing myself to run a Linux desktop full time to get a better grasp of a lot of the things we are going to touch on over the rest of the week. Getting Started I am not suggesting you do the same as me by any stretch as there are easier options and less destructive but I will say taking that full-time step forces you to learn faster on how to make things work on Linux. For this section of this program, I am actually going to deploy a Virtual Machine in Virtual Box on my MacOS machine. I am also going to deploy a desktop version of a Linux distribution, whereas a lot of the Linux servers you will be administering will likely be servers that come with no GUI and everything is shell-based. However, as I said at the start a lot of the tools that we covered throughout this whole program started out on Linux I would also strongly encourage you to take the dive into running that Linux Desktop for that learning experience as well. For the rest of this section, we are going to concentrate on getting a Ubuntu Desktop virtual machine up and running in our Virtual Box environment. Now we could just download Virtual Box and grab the latest Ubuntu ISO from the sites linked and go ahead and build out our desktop environment but that wouldn't be very DevOps of us, would it? Another good reason to use most Linux distributions is that they are free and open-source. We are also choosing Ubuntu as it is probably the most widely used distribution deployed not thinking about mobile devices and enterprise RedHat Enterprise servers. Introducing HashiCorp Vagrant Vagrant is a CLI utility that manages the lifecycle of your virtual machines. We can use vagrant to spin up and down virtual machines across many different platforms including vSphere, Hyper-v, Virtual Box and also Docker. It does have other providers but we will stick with that we are using Virtual Box here so we are good to go. The first thing we need to do is get Vagrant installed on our machine, when you go to the downloads page you will see all the operating systems listed for your choice. HashiCorp Vagrant In this section I'll be using Windows however if you run MacOS you should be able to install it on your system using brew ( brew install vagrant ) which would be the equivalent to apt-get install on Linux distributions. Next up we also need to get Virtual Box installed. Again this can also be installed on many different operating systems again a good reason to choose this and vagrant is that even if you are running Windows, macOS, or Linux then we have you covered here. Something to note that if you're using an M1 Macbook, virtualbox won't be compatible for installation as this only functions on ARM and Intel architecture. Both installations are pretty straightforward. If you have issues both have great communities around them also feel free to reach out or send a message through slack to further assist you! On MacOS you may run the following command as long as you're using a Mac Intel for now. brew install virtualbox Our first VAGRANTFILE The VAGRANTFILE describes the type of machine we want to deploy. It also defines how we want the configuration and provisioning of this machine need to look. When it comes to saving these and organizing your VAGRANTFILEs I tend to put them in their own folders in my workspace. You can see below how this looks on my system. Hopefully following this you will play around with Vagrant and see the ease of spinning up different systems, it is also great for that rabbit hole is known as distro hopping for Linux Desktops. Let's take a look at that VAGRANTFILE then and see what we are building. Vagrant.configure(\"2\") do |config| config.vm.box = \"chenhan/ubuntu-desktop-20.04\" config.vm.provider :virtualbox do |v| v.memory = 8096 v.cpus = 4 v.customize [\"modifyvm\", :id, \"--vram\", \"128mb\"] end end This is a very simple VAGRANTFILE overall we are saying we want a specific \"box\" a box being possibly either a public image or private build of the system you are looking for. You can find a long list of \"boxes\" publicly available here in the public catalog of Vagrant boxes Next line we are saying we want to use a specific provider in this case it is VirtualBox and then we want to define our machine's memory to 8GB and our number of CPUs to 4 . My experience also tells me that you may want to also add the following line if you experience display issues. This will set the video memory to what you want, I would ramp this right up to 128MB but depends on your system. v.customize [\"modifyvm\", :id, \"--vram\", \"\"] I have also placed a copy of this specific vagrant file in the Linux Folder Provisioning our Linux Desktop We are now ready to get our first machine up and running, in your workstations terminal. In my case I am using PowerShell on my Windows machine, navigate to your projects folder and where you will find your VAGRANTFILE. Once there you can type the command vagrant up and if everything is correct then you will see something like the below. Another thing to add here is that the network will be set to NAT on your virtual machine, at this stage we don't really need to know about NAT and I plan to have a whole session talking about in the next section about Networking. But know that it is the easy button when it comes to getting a machine on your home network, it is also the default networking mode on Virtual Box. You can find out more in the Virtual Box documentation Once vagrant up is complete we can now use vagrant ssh to jump straight into the terminal of our new VM. This is where we will do most of our exploring over the next few days but I also want to dive into some customizations for your developer workstation that I have done and it makes your life much simpler when running this as your daily driver, and of course, are you really in DevOps unless you have a cool nonstandard terminal? But just to confirm in Virtual Box you should see the login prompt when you select your VM. Oh and if you made it this far and you have been asking \"WHAT IS THE USERNAME & PASSWORD?\" Username = vagrant Password = vagrant Next we are going to get into some of the commands and what they do, The terminal is going to be the place to make everything happen. Resources Learn the Linux Fundamentals - Part 1 Linux for hackers (don't worry you don't need be a hacker!) There are going to be lots of resources I find as we go through and much like the Go resources I am generally going to be keeping them to FREE content so we can all partake and learn here. As I mentioned next up we will take a look at the commands we might be using on a daily whilst in our Linux environments. See you in the Next Section","title":"1. The Big Picture: DevOps and Linux"},{"location":"Week/01/day03-01/#the-big-picture-devops-and-linux","text":"Linux and DevOps share very similar cultures and perspectives; both are focused on customization and scalability. Both of these aspects of Linux are of particular importance for DevOps. A lot of technologies start on Linux, especially if they are related to software development or managing infrastructure. As well lots of open source projects, especially DevOps tools, were designed to run on Linux from the start. From a DevOps perspective or in fact any operations role perspective you are going to come across Linux I would say mostly. There is a place for WinOps but the majority of the time you are going to be administering and deploying Linux servers. I have been using Linux on a daily basis for a number of years but my go to desktop machine has always been either macOS or Windows. However, when I moved into the Cloud Native role I am in now I took the plunge to make sure that my laptop was fully Linux based and my daily driver, whilst I still needed Windows for some work-based applications at times and a lot of my audio and video gear does not run on Linux I was forcing myself to run a Linux desktop full time to get a better grasp of a lot of the things we are going to touch on over the rest of the week.","title":"The Big Picture: DevOps and Linux"},{"location":"Week/01/day03-01/#getting-started","text":"I am not suggesting you do the same as me by any stretch as there are easier options and less destructive but I will say taking that full-time step forces you to learn faster on how to make things work on Linux. For this section of this program, I am actually going to deploy a Virtual Machine in Virtual Box on my MacOS machine. I am also going to deploy a desktop version of a Linux distribution, whereas a lot of the Linux servers you will be administering will likely be servers that come with no GUI and everything is shell-based. However, as I said at the start a lot of the tools that we covered throughout this whole program started out on Linux I would also strongly encourage you to take the dive into running that Linux Desktop for that learning experience as well. For the rest of this section, we are going to concentrate on getting a Ubuntu Desktop virtual machine up and running in our Virtual Box environment. Now we could just download Virtual Box and grab the latest Ubuntu ISO from the sites linked and go ahead and build out our desktop environment but that wouldn't be very DevOps of us, would it? Another good reason to use most Linux distributions is that they are free and open-source. We are also choosing Ubuntu as it is probably the most widely used distribution deployed not thinking about mobile devices and enterprise RedHat Enterprise servers.","title":"Getting Started"},{"location":"Week/01/day03-01/#introducing-hashicorp-vagrant","text":"Vagrant is a CLI utility that manages the lifecycle of your virtual machines. We can use vagrant to spin up and down virtual machines across many different platforms including vSphere, Hyper-v, Virtual Box and also Docker. It does have other providers but we will stick with that we are using Virtual Box here so we are good to go. The first thing we need to do is get Vagrant installed on our machine, when you go to the downloads page you will see all the operating systems listed for your choice. HashiCorp Vagrant In this section I'll be using Windows however if you run MacOS you should be able to install it on your system using brew ( brew install vagrant ) which would be the equivalent to apt-get install on Linux distributions. Next up we also need to get Virtual Box installed. Again this can also be installed on many different operating systems again a good reason to choose this and vagrant is that even if you are running Windows, macOS, or Linux then we have you covered here. Something to note that if you're using an M1 Macbook, virtualbox won't be compatible for installation as this only functions on ARM and Intel architecture. Both installations are pretty straightforward. If you have issues both have great communities around them also feel free to reach out or send a message through slack to further assist you! On MacOS you may run the following command as long as you're using a Mac Intel for now. brew install virtualbox","title":"Introducing HashiCorp Vagrant"},{"location":"Week/01/day03-01/#our-first-vagrantfile","text":"The VAGRANTFILE describes the type of machine we want to deploy. It also defines how we want the configuration and provisioning of this machine need to look. When it comes to saving these and organizing your VAGRANTFILEs I tend to put them in their own folders in my workspace. You can see below how this looks on my system. Hopefully following this you will play around with Vagrant and see the ease of spinning up different systems, it is also great for that rabbit hole is known as distro hopping for Linux Desktops. Let's take a look at that VAGRANTFILE then and see what we are building. Vagrant.configure(\"2\") do |config| config.vm.box = \"chenhan/ubuntu-desktop-20.04\" config.vm.provider :virtualbox do |v| v.memory = 8096 v.cpus = 4 v.customize [\"modifyvm\", :id, \"--vram\", \"128mb\"] end end This is a very simple VAGRANTFILE overall we are saying we want a specific \"box\" a box being possibly either a public image or private build of the system you are looking for. You can find a long list of \"boxes\" publicly available here in the public catalog of Vagrant boxes Next line we are saying we want to use a specific provider in this case it is VirtualBox and then we want to define our machine's memory to 8GB and our number of CPUs to 4 . My experience also tells me that you may want to also add the following line if you experience display issues. This will set the video memory to what you want, I would ramp this right up to 128MB but depends on your system. v.customize [\"modifyvm\", :id, \"--vram\", \"\"] I have also placed a copy of this specific vagrant file in the Linux Folder","title":"Our first VAGRANTFILE"},{"location":"Week/01/day03-01/#provisioning-our-linux-desktop","text":"We are now ready to get our first machine up and running, in your workstations terminal. In my case I am using PowerShell on my Windows machine, navigate to your projects folder and where you will find your VAGRANTFILE. Once there you can type the command vagrant up and if everything is correct then you will see something like the below. Another thing to add here is that the network will be set to NAT on your virtual machine, at this stage we don't really need to know about NAT and I plan to have a whole session talking about in the next section about Networking. But know that it is the easy button when it comes to getting a machine on your home network, it is also the default networking mode on Virtual Box. You can find out more in the Virtual Box documentation Once vagrant up is complete we can now use vagrant ssh to jump straight into the terminal of our new VM. This is where we will do most of our exploring over the next few days but I also want to dive into some customizations for your developer workstation that I have done and it makes your life much simpler when running this as your daily driver, and of course, are you really in DevOps unless you have a cool nonstandard terminal? But just to confirm in Virtual Box you should see the login prompt when you select your VM. Oh and if you made it this far and you have been asking \"WHAT IS THE USERNAME & PASSWORD?\" Username = vagrant Password = vagrant Next we are going to get into some of the commands and what they do, The terminal is going to be the place to make everything happen.","title":"Provisioning our Linux Desktop"},{"location":"Week/01/day03-01/#resources","text":"Learn the Linux Fundamentals - Part 1 Linux for hackers (don't worry you don't need be a hacker!) There are going to be lots of resources I find as we go through and much like the Go resources I am generally going to be keeping them to FREE content so we can all partake and learn here. As I mentioned next up we will take a look at the commands we might be using on a daily whilst in our Linux environments. See you in the Next Section","title":"Resources"},{"location":"Week/01/day03-02/","text":"Linux Commands for DevOps (Actually everyone) We mentioned on the Previous Section that we are going to be spending a lot of time in the terminal. We will definitely want to get comfortable living in the terminal moving forward but there's nothing to be afraid of! In a short time, you'll find yourself being more productive in terminal and you'll get there with practice. I also mentioned that with our vagrant provisioned VM we can use vagrant ssh and gain access to our box. You will need to be in the same directory as we provisioned it from. For SSH you won't need the username and password, you will only need that if you decide to login to the Virtual Box console. This is where we want to be as per below: Furthermore, if you'd like a small sandbox to test these linux commands you can also use an instant terminal in the browser. Commands Obviously I cannot cover all the commands here, there are pages and pages of documentation that cover these but also if you are ever in your terminal and you just need to understand options to a specific command we have the man pages (short for manual). We can use this to go through each of the commands we touch on during this post to find out more options for each one. We can run man man which will give you the help for manual pages. To escape the man pages you should press q in order to quit from this screen. sudo If you are familar with Windows and the right click run as administrator we can think of sudo as very much this. When you run a command with this command you will be running it as root it will prompt you for the password before running the command. This basically allows you to run any command with privileged levels and should be used with caution. For one off jobs like installing applications or services you might need that sudo command but what if you have several tasks to deal with and you want to live as sudo for a while? This is where you can use sudo su again the same as sudo once entered you will be prompted for your root password. In a test VM like ours this is fine but I would find it very hard for us to be rolling around as root for prolonged periods, bad things can happen. To get out of this elevated position you simply type in exit or use the shorcut CTRL + D . Using clear will help you to keep your terminal clean as we continue prompting more commands in terminal. This obviously can be ahieved by typing the clear command which is going to clear the screen of all previous commands, but you can also type CTRL + L (including MacOS) as a quick shortcut to achieve the same result. Let's now look at some commands where we can actually create things within our system and then visualise them in our terminal, first of all we have mkdir this will allow us to create a folder in our system. With the following command we can create a folder in our home directory called Week-01 mkdir Week-01 With cd this allows us to change directory, so for us to move into our newly created directory we can do this with cd Week-01 tab can also be used to autocomplete the directory available. If we want to get back to where we started we can use cd .. rmdir allows for us to remove the directory, if we run rmdir Week-01 then the folder will be removed (note that this will only work if you have nothing in the folder) I am sure we have all done it where we have navigated to the depths of our file system to a directory and not known where we are. pwd gives us the print out of the working directory, pwd as much as it looks like password it stands for print working directory. We know how to create folders and directories but how do we create files? We can create files using the touch command if we were to run touch Week-01 this would create a file. Ignore mkdir we are going see this again later. ls I can put my house on this, you will use this command so many times, this is going to list the all the files and folders in the current directory. Let's see if we can see that file we just created. How can we find files on our Linux system? locate is going to allow us to search our file system. If we use locate Week-01 it will report back that location of the file. Bonus round is that if you know that the file does exist but you get a blank result then run sudo updatedb which will index all the files in the file system then run your locate again. If you do not have locate available to you, you can install it using this command sudo apt install mlocate What about moving files from one location to another? mv is going to allow you to move your files. Example mv Week-01 DevOpsTraineeProgram will move your file to the DevOpsTraineeProgram folder. We have moved our file but what if we want to rename it now to something else? We can do that using the mv command again... We can simply use mv Week-01 Week-01 to change to upper case or we could use mv Week-01 AnotherWeek to change it altogether, now use ls to check the file. Enough is enough, let's now get rid (delete) of our file and maybe even our directory if we have one created. Introducing the rm command. Simply by running rm AnotherWeek will remove our file. We will also use quite a bit rm -R which will recursively work through a folder or location. We might also use rm -R -f to force the removal of all of those files. Be careful though! If you run rm -R -f / and you decide to add sudo at this specific command, you might as well say goodbye to your system! Always beware of the type of command you're running in terminal, specially when using a priviledged or elevated command with sudo . We have looked at moving files around but what if I just want to copy files from one folder to another, simply put its very similar to the mv command but we use cp (short for copy). We can now run the command cp Week-01 Desktop We have created folders and files but we haven't actually put any contents into our folder, we can add contents a few ways but an easy way is echo we can also use echo to print out a lot of things in our terminal, I personally use echo a lot to print out system variables to know if they are set or not at least. we can use echo \"Hello #DevOpsTraineeProgram\" > Week-01 and this will add this to our file. We can also append to our file using echo \"Commands are fun!\" >> Week-01 Another one of those commands you will use a lot! cat short for concatenate. We can use cat Week-01 to see the contents inside the file. Great for quickly reading those configuration files. If you have a long complex configuration file and you want or need to find something fast in that file vs reading every line then grep is your friend, this will allow us to search your file for a specific word using cat Week-01 | grep \"#DevOpsTraineeProgram\" If you are like me and you use that clear command a lot then you might miss some of the commands previously ran, we can use history to find out all those commands we have run prior. history -c will remove the history. When you run history and you would like to pick a specific command you can use !3 to choose the 3rd command in the list. You are also able to use history | grep \"Command to search for something specific. On servers to trace back when was a command executed, it can be useful to append the date and time to each command in the history file. The following system variable controls this behaviour: HISTTIMEFORMAT=\"%d-%m-%Y %T \" You can easily add to your bash_profile: echo 'export HISTTIMEFORMAT=\"%d-%m-%Y %T \"' >> ~/.bash_profile So as useful to allow the history file grow bigger: echo 'export HISTSIZE=100000' >> ~/.bash_profile echo 'export HISTFILESIZE=10000000' >> ~/.bash_profile Need to change your password? passwd is going allow us to change our password. Note that when you add your password in like this when it is hidden it will not be shown in history however if your command has -p PASSWORD then this will be visible in your history . We might also want to add new users to our system, we can do this with useradd we have to add the user using our sudo command, we can add a new user with sudo useradd NewUser Creating a group again requires sudo and we can use sudo groupadd DevOps then if we want to add our new user to that group we can do this by running sudo usermod -a -G DevOps -a is add and -G is group name. How do we add users to the sudo group, this would be a very rare occassion for this to happen but in order to do this it would be usermod -a -G sudo NewUser Permissions read, write and execute are the permissions we have on all of our files and folders on our Linux system. A full list: 0 = None --- 1 = Execute only --X 2 = Write only -W- 3 = Write & Exectute -WX 4 = Read Only R-- 5 = Read & Execute R-X 6 = Read & Write RW- 7 = Read, Write & Execute RWX You will also see 777 or 775 and these represent the same numbers as the list above but each one represents User - Group - Everyone Let's take a look at our file. ls -al Week-01 you can see the 3 groups mentioned above, user and group has read & write but everyone only has read. We can change this using chmod you might find yourself doing this if you are creating binaries a lot on your systems as well and you need to give the ability to execute those binaries. chmod 750 Week-01 now run ls -al Week-01 if you want to run this for a whole folder then you can use -R to recursively do that. What about changing the owner of the file? We can use chown for this operation, if we wanted to change the ownership of our Week-01 from user vagrant to NewUser we can run sudo chown NewUser Week-01 again -R can be used. A command that you will come across is awk where this comes in real use is when you have an output that you only need specific data from. like running who we get lines with information, but maybe we only need the names. We can run who | awk '{print $1}' to get just a list of that first column. If you are looking to read streams of data from standard input, then generates and executes command lines; meaning it can take output of a command and passes it as argument of another command. xargs is a useful tool for this use case. If for example I want a list of all the Linux user accounts on the system I can run. cut -d: -f1 < /etc/passwd and get the long list we see below. If we want to compact that list I can do so by using xargs in a command like this cut -d: -f1 < /etc/passwd | sort | xargs I didn't mention the cut command either, this allows us to remove sections from each line of a file. It can be used to cut parts of a line by byte position, character and field. The cut -d \" \" -f 2 list.txt command allows us to remove that first letter we have and just display our numbers. There are so many combinations that can be used here with this command, I am sure I have spent too much time trying to use this command when I could have extracted data quicker manually. Also to note if you type a command and you are no longer with happy with it and you want to start again just hit control + c and this will cancel that line and start you fresh. Resources Learn the Linux Fundamentals - Part 1 Linux for hackers (FREE Linux course for beginners) This is a pretty heavy list already but I can safely say that I have used all of these commands in our day to day, be it from an administering Linux servers or in my Linux Desktop, it is very easy when you are in Windows or macOS to navigate the UI but in Linux Servers you won't find pretty UIs, they are simply not there. Everything is done through the terminal. I do also highly recommend completing the course over KodeKloud here . We will touch a few of these topics over the next sections but feel free to complete those and send over your progress through a screenshot if you complete it! See you in the Next Section","title":"2. Linux Commands for DevOps (Actually everyone)"},{"location":"Week/01/day03-02/#linux-commands-for-devops-actually-everyone","text":"We mentioned on the Previous Section that we are going to be spending a lot of time in the terminal. We will definitely want to get comfortable living in the terminal moving forward but there's nothing to be afraid of! In a short time, you'll find yourself being more productive in terminal and you'll get there with practice. I also mentioned that with our vagrant provisioned VM we can use vagrant ssh and gain access to our box. You will need to be in the same directory as we provisioned it from. For SSH you won't need the username and password, you will only need that if you decide to login to the Virtual Box console. This is where we want to be as per below: Furthermore, if you'd like a small sandbox to test these linux commands you can also use an instant terminal in the browser.","title":"Linux Commands for DevOps (Actually everyone)"},{"location":"Week/01/day03-02/#commands","text":"Obviously I cannot cover all the commands here, there are pages and pages of documentation that cover these but also if you are ever in your terminal and you just need to understand options to a specific command we have the man pages (short for manual). We can use this to go through each of the commands we touch on during this post to find out more options for each one. We can run man man which will give you the help for manual pages. To escape the man pages you should press q in order to quit from this screen. sudo If you are familar with Windows and the right click run as administrator we can think of sudo as very much this. When you run a command with this command you will be running it as root it will prompt you for the password before running the command. This basically allows you to run any command with privileged levels and should be used with caution. For one off jobs like installing applications or services you might need that sudo command but what if you have several tasks to deal with and you want to live as sudo for a while? This is where you can use sudo su again the same as sudo once entered you will be prompted for your root password. In a test VM like ours this is fine but I would find it very hard for us to be rolling around as root for prolonged periods, bad things can happen. To get out of this elevated position you simply type in exit or use the shorcut CTRL + D . Using clear will help you to keep your terminal clean as we continue prompting more commands in terminal. This obviously can be ahieved by typing the clear command which is going to clear the screen of all previous commands, but you can also type CTRL + L (including MacOS) as a quick shortcut to achieve the same result. Let's now look at some commands where we can actually create things within our system and then visualise them in our terminal, first of all we have mkdir this will allow us to create a folder in our system. With the following command we can create a folder in our home directory called Week-01 mkdir Week-01 With cd this allows us to change directory, so for us to move into our newly created directory we can do this with cd Week-01 tab can also be used to autocomplete the directory available. If we want to get back to where we started we can use cd .. rmdir allows for us to remove the directory, if we run rmdir Week-01 then the folder will be removed (note that this will only work if you have nothing in the folder) I am sure we have all done it where we have navigated to the depths of our file system to a directory and not known where we are. pwd gives us the print out of the working directory, pwd as much as it looks like password it stands for print working directory. We know how to create folders and directories but how do we create files? We can create files using the touch command if we were to run touch Week-01 this would create a file. Ignore mkdir we are going see this again later. ls I can put my house on this, you will use this command so many times, this is going to list the all the files and folders in the current directory. Let's see if we can see that file we just created. How can we find files on our Linux system? locate is going to allow us to search our file system. If we use locate Week-01 it will report back that location of the file. Bonus round is that if you know that the file does exist but you get a blank result then run sudo updatedb which will index all the files in the file system then run your locate again. If you do not have locate available to you, you can install it using this command sudo apt install mlocate What about moving files from one location to another? mv is going to allow you to move your files. Example mv Week-01 DevOpsTraineeProgram will move your file to the DevOpsTraineeProgram folder. We have moved our file but what if we want to rename it now to something else? We can do that using the mv command again... We can simply use mv Week-01 Week-01 to change to upper case or we could use mv Week-01 AnotherWeek to change it altogether, now use ls to check the file. Enough is enough, let's now get rid (delete) of our file and maybe even our directory if we have one created. Introducing the rm command. Simply by running rm AnotherWeek will remove our file. We will also use quite a bit rm -R which will recursively work through a folder or location. We might also use rm -R -f to force the removal of all of those files. Be careful though! If you run rm -R -f / and you decide to add sudo at this specific command, you might as well say goodbye to your system! Always beware of the type of command you're running in terminal, specially when using a priviledged or elevated command with sudo . We have looked at moving files around but what if I just want to copy files from one folder to another, simply put its very similar to the mv command but we use cp (short for copy). We can now run the command cp Week-01 Desktop We have created folders and files but we haven't actually put any contents into our folder, we can add contents a few ways but an easy way is echo we can also use echo to print out a lot of things in our terminal, I personally use echo a lot to print out system variables to know if they are set or not at least. we can use echo \"Hello #DevOpsTraineeProgram\" > Week-01 and this will add this to our file. We can also append to our file using echo \"Commands are fun!\" >> Week-01 Another one of those commands you will use a lot! cat short for concatenate. We can use cat Week-01 to see the contents inside the file. Great for quickly reading those configuration files. If you have a long complex configuration file and you want or need to find something fast in that file vs reading every line then grep is your friend, this will allow us to search your file for a specific word using cat Week-01 | grep \"#DevOpsTraineeProgram\" If you are like me and you use that clear command a lot then you might miss some of the commands previously ran, we can use history to find out all those commands we have run prior. history -c will remove the history. When you run history and you would like to pick a specific command you can use !3 to choose the 3rd command in the list. You are also able to use history | grep \"Command to search for something specific. On servers to trace back when was a command executed, it can be useful to append the date and time to each command in the history file. The following system variable controls this behaviour: HISTTIMEFORMAT=\"%d-%m-%Y %T \" You can easily add to your bash_profile: echo 'export HISTTIMEFORMAT=\"%d-%m-%Y %T \"' >> ~/.bash_profile So as useful to allow the history file grow bigger: echo 'export HISTSIZE=100000' >> ~/.bash_profile echo 'export HISTFILESIZE=10000000' >> ~/.bash_profile Need to change your password? passwd is going allow us to change our password. Note that when you add your password in like this when it is hidden it will not be shown in history however if your command has -p PASSWORD then this will be visible in your history . We might also want to add new users to our system, we can do this with useradd we have to add the user using our sudo command, we can add a new user with sudo useradd NewUser Creating a group again requires sudo and we can use sudo groupadd DevOps then if we want to add our new user to that group we can do this by running sudo usermod -a -G DevOps -a is add and -G is group name. How do we add users to the sudo group, this would be a very rare occassion for this to happen but in order to do this it would be usermod -a -G sudo NewUser","title":"Commands"},{"location":"Week/01/day03-02/#permissions","text":"read, write and execute are the permissions we have on all of our files and folders on our Linux system. A full list: 0 = None --- 1 = Execute only --X 2 = Write only -W- 3 = Write & Exectute -WX 4 = Read Only R-- 5 = Read & Execute R-X 6 = Read & Write RW- 7 = Read, Write & Execute RWX You will also see 777 or 775 and these represent the same numbers as the list above but each one represents User - Group - Everyone Let's take a look at our file. ls -al Week-01 you can see the 3 groups mentioned above, user and group has read & write but everyone only has read. We can change this using chmod you might find yourself doing this if you are creating binaries a lot on your systems as well and you need to give the ability to execute those binaries. chmod 750 Week-01 now run ls -al Week-01 if you want to run this for a whole folder then you can use -R to recursively do that. What about changing the owner of the file? We can use chown for this operation, if we wanted to change the ownership of our Week-01 from user vagrant to NewUser we can run sudo chown NewUser Week-01 again -R can be used. A command that you will come across is awk where this comes in real use is when you have an output that you only need specific data from. like running who we get lines with information, but maybe we only need the names. We can run who | awk '{print $1}' to get just a list of that first column. If you are looking to read streams of data from standard input, then generates and executes command lines; meaning it can take output of a command and passes it as argument of another command. xargs is a useful tool for this use case. If for example I want a list of all the Linux user accounts on the system I can run. cut -d: -f1 < /etc/passwd and get the long list we see below. If we want to compact that list I can do so by using xargs in a command like this cut -d: -f1 < /etc/passwd | sort | xargs I didn't mention the cut command either, this allows us to remove sections from each line of a file. It can be used to cut parts of a line by byte position, character and field. The cut -d \" \" -f 2 list.txt command allows us to remove that first letter we have and just display our numbers. There are so many combinations that can be used here with this command, I am sure I have spent too much time trying to use this command when I could have extracted data quicker manually. Also to note if you type a command and you are no longer with happy with it and you want to start again just hit control + c and this will cancel that line and start you fresh.","title":"Permissions"},{"location":"Week/01/day03-02/#resources","text":"Learn the Linux Fundamentals - Part 1 Linux for hackers (FREE Linux course for beginners) This is a pretty heavy list already but I can safely say that I have used all of these commands in our day to day, be it from an administering Linux servers or in my Linux Desktop, it is very easy when you are in Windows or macOS to navigate the UI but in Linux Servers you won't find pretty UIs, they are simply not there. Everything is done through the terminal. I do also highly recommend completing the course over KodeKloud here . We will touch a few of these topics over the next sections but feel free to complete those and send over your progress through a screenshot if you complete it! See you in the Next Section","title":"Resources"},{"location":"Week/01/day03-03/","text":"Managing your Linux System, Filesystem & Storage So far we have had a brief overview of Linux and DevOps and then we got our lab environment set up using vagant , we then touched on a small portion of commands that will be in your daily toolkit when in the terminal and getting things done on the Previous Section . Here we are going to look into three key areas of looking after your Linux systems with updates, installing software, understanding what system folders are used for and we will also take a look at storage. Managing Ubuntu & Software The first thing we are going to look at is how we update our operating system. Most of you will be familiar with this process in a Windows OS and macOS, this looks slightly different on a Linux desktop and server. We are going to be looking at the apt package manager, this is what we are going to use on our Ubuntu VM for updates and software installation. Generally, at least on dev workstations, I run this command to make sure that I have the latest available updates from the central repositories, before any software installation. sudo apt-get update Now we have an updated Ubuntu VM with the latest OS updates installed. We now want to get some software installed here. Let's choose figlet which is a program that generates text banners. If we type figlet in our terminal you are going to see that we do not have it installed on our system. You will see from the above though that it does give us some apt install options that we could try. This is because in the default repositories there is a program called figlet. Let's try sudo apt install figlet We can now use our figlet app as you can see below. If we want to remove that or any of our software installations we can also do that via the apt package manager. sudo apt remove figlet There are third party repositories that we can also add to our system, the ones we have access to out of the box are the Ubuntu default repositories. If for example, we wanted to install vagrant on our Ubuntu VM we would not be able to right now and you can see this below on the first command issued. We then add the key to trust the HashiCorp repository, then add the repository to our system. Once we have the HashiCorp repository added we can go ahead and run sudo apt install vagrant and get vagrant installed on our system. There are so many options when it comes to software installation, different options for package managers, built into Ubuntu we could also use snaps for our software installations. Hopefully, this gives you a feel about how to manage your OS and software installations on Linux. File System Explained Linux is made up of configuration files, if you want to change anything then you change these configuration files. On Windows, you have C: drive and that is what we consider the root. On Linux we have / this is where we are going to find the important folders on our Linux system. /bin - Short for binary, the bin folder is where our binaries that your system needs, executables and tools will mostly be found here. /boot - All the files your system needs to boot up. How to boot up, and what drive to boot from. /dev - You can find device information here, this is where you will find pointers to your disk drives sda will be your main OS disk. /etc Likely the most important folder on your Linux system, this is where the majority of your configuration files. /home - this is where you will find your user folders and files. We have our vagrant user folder. This is where you will find your Documents and Desktop folders that we worked in for the commands section. /lib - We mentioned that /bin is where our binaries and executables live, /lib is where you will find the shared libraries for those. /media - This is where we will find removable devices. /mnt - This is a temporary mount point. We will cover more here in the next storage section. /opt - Optional software packages. You will notice here that we have some vagrant and virtual box software stored here. /proc - Kernel & process information, similar to /dev /root - To gain access you will need to sudo into this folder. The home folder for root. /run -Placeholder for application states. /sbin - Sudo bin, similar to the bin folder but these tools are intended for elevated superuser privileges on the system. /tmp - temporary files. /usr - If we as a standard user have installed software packages it would generally be installed in the /usr/bin location. /var - Our applications get installed in a bin folder. We need somewhere to store all of the log files this is /var Storage When we come to a Linux system or any system we might want to know the available disks and how much free space we have on those disks. The next few commands will help us identify and use and manage storage. lsblk List Block devices. sda is our physical disk and then sda1, sda2, sda3 are our partitions on that disk. df gives us a little more detail about those partitions, total, used and available. You can parse other flags here I generally use df -h to give us a human output of the data. If you were adding a new disk to your system and this is the same in Windows you would need to format the disk in disk management, in the Linux terminal you can do this by using the sudo mkfs -t ext4 /dev/sdb with sdb relating to our newly added disk. We would then need to mount our newly formatted disk so that it was useable. We would do this in our /mnt folder previously mentioned and we would create a directory there with sudo mkdir NewDisk we would then use sudo mount /dev/sdb newdisk to mount the disk to that location. It is also possible that you will need to unmount storage from your system safely vs just pulling it from the configuration. We can do this with sudo umount /dev/sdb If you did not want to unmount that disk and you were going to be using this disk for a database or some other persistent use case then you want it to be there when you reboot your system. For this to happen we need to add this disk to our /etc/fstab configuration file for it to persist, if you don't it won't be useable when the machine reboots and you would manually have to go through the above process. The data will still be there on the disk but it won't automount unless you add the configuration to this file. Once you have edited the fstab configuration file you can check your workings with sudo mount -a if no errors then your changes will now be persistent across restarts. We will cover how you would edit a file using a text editor in a future session. Resources Linux File System/Structure Explained! The Linux File System explained in 1,233 seconds // Linux for Hackers // EP 2 See you in the Next Section","title":"3. Managing your Linux System, Filesystem & Storage - Day 16"},{"location":"Week/01/day03-03/#managing-your-linux-system-filesystem-storage","text":"So far we have had a brief overview of Linux and DevOps and then we got our lab environment set up using vagant , we then touched on a small portion of commands that will be in your daily toolkit when in the terminal and getting things done on the Previous Section . Here we are going to look into three key areas of looking after your Linux systems with updates, installing software, understanding what system folders are used for and we will also take a look at storage.","title":"Managing your Linux System, Filesystem &amp; Storage"},{"location":"Week/01/day03-03/#managing-ubuntu-software","text":"The first thing we are going to look at is how we update our operating system. Most of you will be familiar with this process in a Windows OS and macOS, this looks slightly different on a Linux desktop and server. We are going to be looking at the apt package manager, this is what we are going to use on our Ubuntu VM for updates and software installation. Generally, at least on dev workstations, I run this command to make sure that I have the latest available updates from the central repositories, before any software installation. sudo apt-get update Now we have an updated Ubuntu VM with the latest OS updates installed. We now want to get some software installed here. Let's choose figlet which is a program that generates text banners. If we type figlet in our terminal you are going to see that we do not have it installed on our system. You will see from the above though that it does give us some apt install options that we could try. This is because in the default repositories there is a program called figlet. Let's try sudo apt install figlet We can now use our figlet app as you can see below. If we want to remove that or any of our software installations we can also do that via the apt package manager. sudo apt remove figlet There are third party repositories that we can also add to our system, the ones we have access to out of the box are the Ubuntu default repositories. If for example, we wanted to install vagrant on our Ubuntu VM we would not be able to right now and you can see this below on the first command issued. We then add the key to trust the HashiCorp repository, then add the repository to our system. Once we have the HashiCorp repository added we can go ahead and run sudo apt install vagrant and get vagrant installed on our system. There are so many options when it comes to software installation, different options for package managers, built into Ubuntu we could also use snaps for our software installations. Hopefully, this gives you a feel about how to manage your OS and software installations on Linux.","title":"Managing Ubuntu &amp; Software"},{"location":"Week/01/day03-03/#file-system-explained","text":"Linux is made up of configuration files, if you want to change anything then you change these configuration files. On Windows, you have C: drive and that is what we consider the root. On Linux we have / this is where we are going to find the important folders on our Linux system. /bin - Short for binary, the bin folder is where our binaries that your system needs, executables and tools will mostly be found here. /boot - All the files your system needs to boot up. How to boot up, and what drive to boot from. /dev - You can find device information here, this is where you will find pointers to your disk drives sda will be your main OS disk. /etc Likely the most important folder on your Linux system, this is where the majority of your configuration files. /home - this is where you will find your user folders and files. We have our vagrant user folder. This is where you will find your Documents and Desktop folders that we worked in for the commands section. /lib - We mentioned that /bin is where our binaries and executables live, /lib is where you will find the shared libraries for those. /media - This is where we will find removable devices. /mnt - This is a temporary mount point. We will cover more here in the next storage section. /opt - Optional software packages. You will notice here that we have some vagrant and virtual box software stored here. /proc - Kernel & process information, similar to /dev /root - To gain access you will need to sudo into this folder. The home folder for root. /run -Placeholder for application states. /sbin - Sudo bin, similar to the bin folder but these tools are intended for elevated superuser privileges on the system. /tmp - temporary files. /usr - If we as a standard user have installed software packages it would generally be installed in the /usr/bin location. /var - Our applications get installed in a bin folder. We need somewhere to store all of the log files this is /var","title":"File System Explained"},{"location":"Week/01/day03-03/#storage","text":"When we come to a Linux system or any system we might want to know the available disks and how much free space we have on those disks. The next few commands will help us identify and use and manage storage. lsblk List Block devices. sda is our physical disk and then sda1, sda2, sda3 are our partitions on that disk. df gives us a little more detail about those partitions, total, used and available. You can parse other flags here I generally use df -h to give us a human output of the data. If you were adding a new disk to your system and this is the same in Windows you would need to format the disk in disk management, in the Linux terminal you can do this by using the sudo mkfs -t ext4 /dev/sdb with sdb relating to our newly added disk. We would then need to mount our newly formatted disk so that it was useable. We would do this in our /mnt folder previously mentioned and we would create a directory there with sudo mkdir NewDisk we would then use sudo mount /dev/sdb newdisk to mount the disk to that location. It is also possible that you will need to unmount storage from your system safely vs just pulling it from the configuration. We can do this with sudo umount /dev/sdb If you did not want to unmount that disk and you were going to be using this disk for a database or some other persistent use case then you want it to be there when you reboot your system. For this to happen we need to add this disk to our /etc/fstab configuration file for it to persist, if you don't it won't be useable when the machine reboots and you would manually have to go through the above process. The data will still be there on the disk but it won't automount unless you add the configuration to this file. Once you have edited the fstab configuration file you can check your workings with sudo mount -a if no errors then your changes will now be persistent across restarts. We will cover how you would edit a file using a text editor in a future session.","title":"Storage"},{"location":"Week/01/day03-03/#resources","text":"Linux File System/Structure Explained! The Linux File System explained in 1,233 seconds // Linux for Hackers // EP 2 See you in the Next Section","title":"Resources"},{"location":"Week/01/day03-04/","text":"Text Editors - nano vs vim The majority of your Linux systems are going to be servers and these are not going to have a GUI. I also mentioned in the last session that Linux is mostly made up of configuration files, to make changes you are going to need to be able to edit those configuration files to change anything on the system. There are lots of options out there but I think we should cover probably the two most common terminal text editors. I have used both of these editors and for me, I find nano the easy button when it comes to quick changes but vim has such a broad set of capabilities. nano Not available on every system. Great for getting started. If you run nano DevOpsTraineeProgram.txt we will create a new file with nothing in, from here we can add our text and we have our instructions below for what we want to do with that file. We can now use control x + enter and then run ls you can now see our new text file. If we then decide to run cat against that file to read our file. We can then use that same nano DevOpsTraineeProgram.txt to add additional text or modify your file. For me, nano is super easy when it comes to getting small changes done on configuration files. vim Possibly the most common text editor around? A sibling of the UNIX text editor vi from 1976 we get a lot of functionality with vim. Pretty much supported on every single Linux distribution. Incredibly powerful! You can likely find a full 7-hour course just covering vim. We can jump into vim with the vim command or if we want to edit our new txt file we could run vim DevOpsTraineeProgram.txt but you are going to first see the lack of help menus at the bottom. The first question might be \"How do I exit vim?\" that is going to be escape and if we have not made any changes then it will be :q You start in normal mode, there are other modes command, normal, visual, insert , if we want to add the text we will need to switch from normal to insert we need to press i if you have added some text and would like to save these changes then you would hit escape and then :wq You can confirm this with the cat command to check you have saved those changes. There is some cool fast functionality with vim that allows you to do menial tasks very quickly if you know the shortcuts which is a lecture in itself. Let's say we have added a list of repeated words and we now need to change that, maybe it's a configuration file and we repeat a network name and now this has changed and we quickly want to change this. I am using the word day for this example. Now we want to replace that word with DevOpsTraineeProgram, we can do this by hitting esc and typing :%s/Day/DevOpsTraineeProgram The outcome when you hit enter is that the word day is then replaced with DevOpsTraineeProgram. Copy and Paste was a big eye-opener for me. Copy is not copy in here but it is called yank . we can copy using yy on our keyboard in normal mode. p paste on the same line, P paste on a new line. You can also delete these lines by choosing the number of lines you wish to delete followed by dd There is also likely a time you will need to search a file, now we can use grep as mentioned in a previous session but we can also use vim. we can use /word and this will find the first match, to navigate through to the next you will use the n key and so on. For vim this is not even touching the surface, the biggest advice I can give is to get hands-on and use vim wherever possible. A common interview question is what is your favourite text editor in Linux and I would make sure you have at least this knowledge of both so you can answer, it is fine to say nano because it's simple. At least you show competence in understanding what a text editor is. But get hands-on with them to be more proficient. Another pointer to navigate around in vim we can use H,J,K,L as well as our arrow keys. Resources VIM - Tutorial para principiantes - El MEJOR editor de texto - PeladoNerd) Vim in 100 Seconds Vim tutorial Learn the Linux Fundamentals - Part 1 See you in the Next Section","title":"4. Text Editors - Nano vs Vim"},{"location":"Week/01/day03-04/#text-editors-nano-vs-vim","text":"The majority of your Linux systems are going to be servers and these are not going to have a GUI. I also mentioned in the last session that Linux is mostly made up of configuration files, to make changes you are going to need to be able to edit those configuration files to change anything on the system. There are lots of options out there but I think we should cover probably the two most common terminal text editors. I have used both of these editors and for me, I find nano the easy button when it comes to quick changes but vim has such a broad set of capabilities.","title":"Text Editors - nano vs vim"},{"location":"Week/01/day03-04/#nano","text":"Not available on every system. Great for getting started. If you run nano DevOpsTraineeProgram.txt we will create a new file with nothing in, from here we can add our text and we have our instructions below for what we want to do with that file. We can now use control x + enter and then run ls you can now see our new text file. If we then decide to run cat against that file to read our file. We can then use that same nano DevOpsTraineeProgram.txt to add additional text or modify your file. For me, nano is super easy when it comes to getting small changes done on configuration files.","title":"nano"},{"location":"Week/01/day03-04/#vim","text":"Possibly the most common text editor around? A sibling of the UNIX text editor vi from 1976 we get a lot of functionality with vim. Pretty much supported on every single Linux distribution. Incredibly powerful! You can likely find a full 7-hour course just covering vim. We can jump into vim with the vim command or if we want to edit our new txt file we could run vim DevOpsTraineeProgram.txt but you are going to first see the lack of help menus at the bottom. The first question might be \"How do I exit vim?\" that is going to be escape and if we have not made any changes then it will be :q You start in normal mode, there are other modes command, normal, visual, insert , if we want to add the text we will need to switch from normal to insert we need to press i if you have added some text and would like to save these changes then you would hit escape and then :wq You can confirm this with the cat command to check you have saved those changes. There is some cool fast functionality with vim that allows you to do menial tasks very quickly if you know the shortcuts which is a lecture in itself. Let's say we have added a list of repeated words and we now need to change that, maybe it's a configuration file and we repeat a network name and now this has changed and we quickly want to change this. I am using the word day for this example. Now we want to replace that word with DevOpsTraineeProgram, we can do this by hitting esc and typing :%s/Day/DevOpsTraineeProgram The outcome when you hit enter is that the word day is then replaced with DevOpsTraineeProgram. Copy and Paste was a big eye-opener for me. Copy is not copy in here but it is called yank . we can copy using yy on our keyboard in normal mode. p paste on the same line, P paste on a new line. You can also delete these lines by choosing the number of lines you wish to delete followed by dd There is also likely a time you will need to search a file, now we can use grep as mentioned in a previous session but we can also use vim. we can use /word and this will find the first match, to navigate through to the next you will use the n key and so on. For vim this is not even touching the surface, the biggest advice I can give is to get hands-on and use vim wherever possible. A common interview question is what is your favourite text editor in Linux and I would make sure you have at least this knowledge of both so you can answer, it is fine to say nano because it's simple. At least you show competence in understanding what a text editor is. But get hands-on with them to be more proficient. Another pointer to navigate around in vim we can use H,J,K,L as well as our arrow keys.","title":"vim"},{"location":"Week/01/day03-04/#resources","text":"VIM - Tutorial para principiantes - El MEJOR editor de texto - PeladoNerd) Vim in 100 Seconds Vim tutorial Learn the Linux Fundamentals - Part 1 See you in the Next Section","title":"Resources"},{"location":"Week/01/day03-05/","text":"SSH & Web Server As we have mentioned throughout you are going to most likely be managing lots of remote Linux servers, because of this, you will need to make sure that your connectivity to these remote servers is secure. In this section, we want to cover some of the basics of SSH that everyone should know that will help you with that secure tunnel to your remote systems. Setting up a connection with SSH Transferring files Create your private key SSH introduction Secure shell Networking Protocol Allows secure communications Can secure any network service Typically used for remote command-line access In our environment, if you have been following along we have been using SSH already but this was all configured and automated through our vagrant configuration so we only had to run vagrant ssh and we gained access to our remote virtual machine. If our remote machine was not on the same system as our workstation and was in a remote location, maybe a cloud-based system or running in a data centre that we could only access over the internet we would need a secure way of being able to access the system to manage it. SSH provides a secure tunnel between client and server so that nothing can be intercepted by bad actors. The server has a server-side SSH service always running and listening on a specific TCP port (22). If we use our client to connect with the correct credentials or SSH key then we gain access to that server. Adding a bridged network adapter to our system In order for us to use this with our current virtual box VM, we need to add a bridged network adapter to our machine. Power down your virtual machine, right-click on your machine within Virtual Box and select settings. In the new window then select networking. Now power your machine back on and you will now have an IP address on your local machine. You can confirm this with the ip addr command. Confirming SSH server is running We know SSH is already configured on our machine as we have been using it with vagrant but we can confirm by running sudo systemctl status ssh If your system does not have the SSH server then you can install it by issuing this command sudo apt install openssh-server You then want to make sure that our SSH is allowed if the firewall is running. We can do this with sudo ufw allow ssh this is not required on our configuration as we automated this with our vagrant provisioning. Remote Access - SSH Password Now that we have our SSH Server listening out on port 22 for any incoming connection requests and we have added the bridged networking we could use putty or an SSH client on our local machine to connect into our system using SSH. For Windows, you may use PuTTY: However, I do still highly recommend using Linux based system as they're easy to connect out of the box through terminal with the ssh command. Then hit open, if this is the first time you have connected to this system via this IP address you will get this warning. We know that this is our system so you can choose yes. We are then prompted for our username (vagrant) and password (default password - vagrant) Below you will see we are now using our SSH client (Putty) to connect to our machine using username and password. At this stage, we are connected to our VM from our remote client and we can issue our commands on our system. Remote Access - SSH Key The above is an easy way to gain access to your systems however it still relies on username and password, if some malicious actor was to gain access to this information plus the public address or IP of your system then it could be easily compromised. This is where SSH keys are preferred. SSH Keys means that we provide a key pair so that both the client and server know that this is a trusted device. Creating a key is easy. On our local machine (Windows) We can issue the following command in fact if you have an ssh-client installed on any system I believe this same command should work. ssh-keygen -t ed25519 Alternatively, depending on the system you may want to create an RSA key instead. ssh-keygen -t rsa I am not going to get into what ed25519 or RSA is and means here but you can have a search if you want to learn more about cryptography or you can read more about the difference between both of them on the following resource: - Is RSA key considered secure today? At this point we have our created SSH key stored in C:\\Users\\admin/.ssh/ But in order to link this with our Linux VM we need to copy the key. We can do this by using the ssh-copy-id vagrant@192.168.169.135 I used Powershell to create my keys on the Windows client here but there is no ssh-copy-id available. There are ways in which you can do this on Windows and a small search online will find you an alternative, but I will just use git bash on the Windows machine to make the copy. We can now go back to Powershell to test that our connection now works with our SSH Keys and no password is required. ssh vagrant@192.168.169.135 We could secure this further if needed by using a passphrase. We could also go one step further saying that no passwords at all meaning only key pairs over SSH would be allowed. You can make this happen in the following configuration file. sudo vi /etc/ssh/sshd_config there is a line in here with PasswordAuthentication yes this will be # commented out, you should uncomment and change the yes to no. You will then need to reload the SSH service with sudo systemctl reload sshd Setting up a Web Server Not specifically related to what we have just done with SSH above but I wanted to include this as this is again another task that you might find a little daunting but it really should not be. We have our Linux playground VM and at this stage, we want to add an apache webserver to our VM so that we can host a simple website from it that serves out to my home network. Note that this web page will not be accessible from the internet, this can be done but it will not be covered here. You might also see this referred to as a LAMP stack. L inux Operating System A pache Web Server m ySQL database P HP Apache2 Apache2 is an open-source HTTP server. We can install apache2 with the following command. sudo apt-get install apache2 To confirm that apache2 is installed correctly we can run sudo service apache2 restart Then using the bridged network address from the SSH walkthrough open a browser and go to that address but for this section. Furthermore feel free to reach out over slack ! In this case, we can deploy an instant cloud sandbox for you to work on it without the need to install anything on your local machine. Everything through the cloud! mySQL MySQL is a database in which we will be storing our data for our simple website. To get MySQL installed we should use the following command sudo apt-get install mysql-server PHP PHP is a server-side scripting language, we will use this to interact with a MySQL database. The final installation is to get PHP and dependencies installed using sudo apt-get install php libapache2-mod-php php-mysql The first configuration change we want to make it out of the box apache is using index.html and we want it to use index.php instead. We are going to use sudo nano /etc/apache2/mods-enabled/dir.conf and we are going to move index.php to the first item in the list. Restart the apache2 service sudo systemctl restart apache2 Now let's confirm that our system is configured correctly for PHP. Create the following file using this command, this will open a blank file in nano. sudo nano /var/www/html/90Days.php then copy the following and use control + x to exit and save your file. <?php phpinfo(); ?> Now navigate to your Linux VM IP again with the additional DevopsTraining.php on the end of the URL. http://192.168.169.135/DevopsTraining.php you should see something similar to the below if PHP is configured correctly. WordPress Installation I then walked through this tutorial to get WordPress up on our LAMP stack, some commands are shown below if not shown correctly in the walkthrough How to install wordpress on Ubuntu with LAMP `sudo mysql -u root -p` `CREATE DATABASE wordpressdb;` `CREATE USER 'admin-user'@'localhost' IDENTIFIED BY 'password';` `GRANT ALL PRIVILEGES ON wordpressdb.* TO 'admin-user'@'localhost';` `FLUSH PRIVILEGES;` `EXIT;` `sudo apt install php-curl php-gd php-mbstring php-xml php-xmlrpc php-soap php-intl php-zip` `sudo systemctl restart apache2` `cd /var/www` `sudo curl -O https://wordpress.org/latest.tar.gz` `sudo tar -xvf latest.tar.gz` `sudo rm latest.tar.gz` At this point you are Step 4 in the linked article, you will need to follow the steps to make sure all correct permissions are in place for the WordPress directory. Because this is internal only you do not need to \"generate security keys\" in this step. Move to Step 5 which is changing the Apache configuration to WordPress. Then providing everything is configured correctly you will be able to access via your internal network address and run through the WordPress installation. Resources Client SSH GUI - Remmina The Beginner's guide to SSH See you in the Next Section \ud83d\udea7","title":"5. SSH & Web Server"},{"location":"Week/01/day03-05/#ssh-web-server","text":"As we have mentioned throughout you are going to most likely be managing lots of remote Linux servers, because of this, you will need to make sure that your connectivity to these remote servers is secure. In this section, we want to cover some of the basics of SSH that everyone should know that will help you with that secure tunnel to your remote systems. Setting up a connection with SSH Transferring files Create your private key","title":"SSH &amp; Web Server"},{"location":"Week/01/day03-05/#ssh-introduction","text":"Secure shell Networking Protocol Allows secure communications Can secure any network service Typically used for remote command-line access In our environment, if you have been following along we have been using SSH already but this was all configured and automated through our vagrant configuration so we only had to run vagrant ssh and we gained access to our remote virtual machine. If our remote machine was not on the same system as our workstation and was in a remote location, maybe a cloud-based system or running in a data centre that we could only access over the internet we would need a secure way of being able to access the system to manage it. SSH provides a secure tunnel between client and server so that nothing can be intercepted by bad actors. The server has a server-side SSH service always running and listening on a specific TCP port (22). If we use our client to connect with the correct credentials or SSH key then we gain access to that server.","title":"SSH introduction"},{"location":"Week/01/day03-05/#adding-a-bridged-network-adapter-to-our-system","text":"In order for us to use this with our current virtual box VM, we need to add a bridged network adapter to our machine. Power down your virtual machine, right-click on your machine within Virtual Box and select settings. In the new window then select networking. Now power your machine back on and you will now have an IP address on your local machine. You can confirm this with the ip addr command.","title":"Adding a bridged network adapter to our system"},{"location":"Week/01/day03-05/#confirming-ssh-server-is-running","text":"We know SSH is already configured on our machine as we have been using it with vagrant but we can confirm by running sudo systemctl status ssh If your system does not have the SSH server then you can install it by issuing this command sudo apt install openssh-server You then want to make sure that our SSH is allowed if the firewall is running. We can do this with sudo ufw allow ssh this is not required on our configuration as we automated this with our vagrant provisioning.","title":"Confirming SSH server is running"},{"location":"Week/01/day03-05/#remote-access-ssh-password","text":"Now that we have our SSH Server listening out on port 22 for any incoming connection requests and we have added the bridged networking we could use putty or an SSH client on our local machine to connect into our system using SSH. For Windows, you may use PuTTY: However, I do still highly recommend using Linux based system as they're easy to connect out of the box through terminal with the ssh command. Then hit open, if this is the first time you have connected to this system via this IP address you will get this warning. We know that this is our system so you can choose yes. We are then prompted for our username (vagrant) and password (default password - vagrant) Below you will see we are now using our SSH client (Putty) to connect to our machine using username and password. At this stage, we are connected to our VM from our remote client and we can issue our commands on our system.","title":"Remote Access - SSH Password"},{"location":"Week/01/day03-05/#remote-access-ssh-key","text":"The above is an easy way to gain access to your systems however it still relies on username and password, if some malicious actor was to gain access to this information plus the public address or IP of your system then it could be easily compromised. This is where SSH keys are preferred. SSH Keys means that we provide a key pair so that both the client and server know that this is a trusted device. Creating a key is easy. On our local machine (Windows) We can issue the following command in fact if you have an ssh-client installed on any system I believe this same command should work. ssh-keygen -t ed25519 Alternatively, depending on the system you may want to create an RSA key instead. ssh-keygen -t rsa I am not going to get into what ed25519 or RSA is and means here but you can have a search if you want to learn more about cryptography or you can read more about the difference between both of them on the following resource: - Is RSA key considered secure today? At this point we have our created SSH key stored in C:\\Users\\admin/.ssh/ But in order to link this with our Linux VM we need to copy the key. We can do this by using the ssh-copy-id vagrant@192.168.169.135 I used Powershell to create my keys on the Windows client here but there is no ssh-copy-id available. There are ways in which you can do this on Windows and a small search online will find you an alternative, but I will just use git bash on the Windows machine to make the copy. We can now go back to Powershell to test that our connection now works with our SSH Keys and no password is required. ssh vagrant@192.168.169.135 We could secure this further if needed by using a passphrase. We could also go one step further saying that no passwords at all meaning only key pairs over SSH would be allowed. You can make this happen in the following configuration file. sudo vi /etc/ssh/sshd_config there is a line in here with PasswordAuthentication yes this will be # commented out, you should uncomment and change the yes to no. You will then need to reload the SSH service with sudo systemctl reload sshd","title":"Remote Access - SSH Key"},{"location":"Week/01/day03-05/#setting-up-a-web-server","text":"Not specifically related to what we have just done with SSH above but I wanted to include this as this is again another task that you might find a little daunting but it really should not be. We have our Linux playground VM and at this stage, we want to add an apache webserver to our VM so that we can host a simple website from it that serves out to my home network. Note that this web page will not be accessible from the internet, this can be done but it will not be covered here. You might also see this referred to as a LAMP stack. L inux Operating System A pache Web Server m ySQL database P HP","title":"Setting up a Web Server"},{"location":"Week/01/day03-05/#apache2","text":"Apache2 is an open-source HTTP server. We can install apache2 with the following command. sudo apt-get install apache2 To confirm that apache2 is installed correctly we can run sudo service apache2 restart Then using the bridged network address from the SSH walkthrough open a browser and go to that address but for this section. Furthermore feel free to reach out over slack ! In this case, we can deploy an instant cloud sandbox for you to work on it without the need to install anything on your local machine. Everything through the cloud!","title":"Apache2"},{"location":"Week/01/day03-05/#mysql","text":"MySQL is a database in which we will be storing our data for our simple website. To get MySQL installed we should use the following command sudo apt-get install mysql-server","title":"mySQL"},{"location":"Week/01/day03-05/#php","text":"PHP is a server-side scripting language, we will use this to interact with a MySQL database. The final installation is to get PHP and dependencies installed using sudo apt-get install php libapache2-mod-php php-mysql The first configuration change we want to make it out of the box apache is using index.html and we want it to use index.php instead. We are going to use sudo nano /etc/apache2/mods-enabled/dir.conf and we are going to move index.php to the first item in the list. Restart the apache2 service sudo systemctl restart apache2 Now let's confirm that our system is configured correctly for PHP. Create the following file using this command, this will open a blank file in nano. sudo nano /var/www/html/90Days.php then copy the following and use control + x to exit and save your file. <?php phpinfo(); ?> Now navigate to your Linux VM IP again with the additional DevopsTraining.php on the end of the URL. http://192.168.169.135/DevopsTraining.php you should see something similar to the below if PHP is configured correctly.","title":"PHP"},{"location":"Week/01/day03-05/#wordpress-installation","text":"I then walked through this tutorial to get WordPress up on our LAMP stack, some commands are shown below if not shown correctly in the walkthrough How to install wordpress on Ubuntu with LAMP `sudo mysql -u root -p` `CREATE DATABASE wordpressdb;` `CREATE USER 'admin-user'@'localhost' IDENTIFIED BY 'password';` `GRANT ALL PRIVILEGES ON wordpressdb.* TO 'admin-user'@'localhost';` `FLUSH PRIVILEGES;` `EXIT;` `sudo apt install php-curl php-gd php-mbstring php-xml php-xmlrpc php-soap php-intl php-zip` `sudo systemctl restart apache2` `cd /var/www` `sudo curl -O https://wordpress.org/latest.tar.gz` `sudo tar -xvf latest.tar.gz` `sudo rm latest.tar.gz` At this point you are Step 4 in the linked article, you will need to follow the steps to make sure all correct permissions are in place for the WordPress directory. Because this is internal only you do not need to \"generate security keys\" in this step. Move to Step 5 which is changing the Apache configuration to WordPress. Then providing everything is configured correctly you will be able to access via your internal network address and run through the WordPress installation.","title":"WordPress Installation"},{"location":"Week/01/day03-05/#resources","text":"Client SSH GUI - Remmina The Beginner's guide to SSH See you in the Next Section \ud83d\udea7","title":"Resources"}]}